{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1= open('D1.txt', 'r')\n",
    "f2= open('D2.txt', 'r')\n",
    "f3= open('D3.txt', 'r')\n",
    "f4= open('D4.txt', 'r')\n",
    "text1=f1.read()\n",
    "text2=f2.read()\n",
    "text3=f3.read()\n",
    "text4=f4.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'order',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'evolution',\n",
       " 'of',\n",
       " 'user',\n",
       " 'preference',\n",
       " 'we',\n",
       " 'should',\n",
       " 'learn',\n",
       " 'user-item',\n",
       " 'embeddings',\n",
       " 'based',\n",
       " 'on',\n",
       " 'time-ordered',\n",
       " 'item',\n",
       " 'purchasing',\n",
       " 'sequences',\n",
       " 'which',\n",
       " 'is',\n",
       " 'defined',\n",
       " 'as',\n",
       " 'Sequential',\n",
       " 'Recommendation',\n",
       " 'SR',\n",
       " 'problem',\n",
       " 'Existing',\n",
       " 'methods',\n",
       " 'leverage',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'to',\n",
       " 'model',\n",
       " 'item',\n",
       " 'transitions',\n",
       " 'However',\n",
       " 'most',\n",
       " 'of',\n",
       " 'them',\n",
       " 'ignore',\n",
       " 'crucial',\n",
       " 'temporal',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'which',\n",
       " 'are',\n",
       " 'latent',\n",
       " 'in',\n",
       " 'evolving',\n",
       " 'user-item',\n",
       " 'interactions',\n",
       " 'and',\n",
       " 'coexist',\n",
       " 'with',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'Therefore',\n",
       " 'we',\n",
       " 'propose',\n",
       " 'to',\n",
       " 'unify',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'temporal',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'recommendation',\n",
       " 'which',\n",
       " 'is',\n",
       " 'rather',\n",
       " 'challenging',\n",
       " 'Firstly',\n",
       " 'it',\n",
       " 'is',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'simultaneously',\n",
       " 'encode',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'Secondly',\n",
       " 'it',\n",
       " 'is',\n",
       " 'non-trivial',\n",
       " 'to',\n",
       " 'express',\n",
       " 'the',\n",
       " 'temporal',\n",
       " 'effects',\n",
       " 'of',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'Hence',\n",
       " 'we',\n",
       " 'design',\n",
       " 'a',\n",
       " 'new',\n",
       " 'framework',\n",
       " 'Temporal',\n",
       " 'Graph',\n",
       " 'Sequential',\n",
       " 'Recommender',\n",
       " 'TGSRec',\n",
       " 'upon',\n",
       " 'our',\n",
       " 'defined',\n",
       " 'continuous-time',\n",
       " 'bipartite',\n",
       " 'graph',\n",
       " 'We',\n",
       " 'propose',\n",
       " 'a',\n",
       " 'novel',\n",
       " 'Temporal',\n",
       " 'Collaborative',\n",
       " 'Transformer',\n",
       " 'TCT',\n",
       " 'layer',\n",
       " 'in',\n",
       " 'TGSRec',\n",
       " 'which',\n",
       " 'advances',\n",
       " 'the',\n",
       " 'self-attention',\n",
       " 'mechanism',\n",
       " 'by',\n",
       " 'adopting',\n",
       " 'a',\n",
       " 'novel',\n",
       " 'collaborative',\n",
       " 'attention',\n",
       " 'TCT',\n",
       " 'layer',\n",
       " 'can',\n",
       " 'simultaneously',\n",
       " 'capture',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'from',\n",
       " 'both',\n",
       " 'users',\n",
       " 'and',\n",
       " 'items',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'considering',\n",
       " 'temporal',\n",
       " 'dynamics',\n",
       " 'inside',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'We',\n",
       " 'propagate',\n",
       " 'the',\n",
       " 'information',\n",
       " 'learned',\n",
       " 'from',\n",
       " 'TCT',\n",
       " 'layer',\n",
       " 'over',\n",
       " 'the',\n",
       " 'temporal',\n",
       " 'graph',\n",
       " 'to',\n",
       " 'unify',\n",
       " 'sequential',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'temporal',\n",
       " 'collaborative',\n",
       " 'signals',\n",
       " 'Empirical',\n",
       " 'results',\n",
       " 'on',\n",
       " 'five',\n",
       " 'datasets',\n",
       " 'show',\n",
       " 'that',\n",
       " 'modelname',\n",
       " 'significantly',\n",
       " 'outperforms',\n",
       " 'other',\n",
       " 'baselines',\n",
       " 'in',\n",
       " 'average',\n",
       " 'up',\n",
       " 'to',\n",
       " '22.5%',\n",
       " 'and',\n",
       " '22.1%',\n",
       " 'absolute',\n",
       " 'improvements',\n",
       " 'in',\n",
       " 'Recall',\n",
       " '10',\n",
       " 'and',\n",
       " 'MRR',\n",
       " 'respectively']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpReg2 = nltk.RegexpTokenizer('(?:\\w\\.)+|\\d+(?:\\.\\d+)?%?|(?:\\w|[`-]\\w)+|\\w+')\n",
    "text2=text2.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "Termes2 = ExpReg2.tokenize(text2)\n",
    "Termes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExpReg1 = nltk.RegexpTokenizer('\\w+(?:-\\w+)*|\\$[\\d.]+|\\S+') # \\w : équivalent à [a-zA-Z0-9_]\n",
    "text1=text1.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "Termes1 = ExpReg2.tokenize(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Motivated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'vast',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'knowledge',\n",
       " 'graph',\n",
       " 'and',\n",
       " 'the',\n",
       " 'increasing',\n",
       " 'demand',\n",
       " 'in',\n",
       " 'education',\n",
       " 'domain',\n",
       " 'we',\n",
       " 'propose',\n",
       " 'a',\n",
       " 'system',\n",
       " 'called',\n",
       " 'KnowEdu',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'construct',\n",
       " 'knowledge',\n",
       " 'graph',\n",
       " 'for',\n",
       " 'education',\n",
       " 'By',\n",
       " 'leveraging',\n",
       " 'on',\n",
       " 'heterogeneous',\n",
       " 'data',\n",
       " 'e.g.',\n",
       " 'pedagogical',\n",
       " 'data',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'assessment',\n",
       " 'data',\n",
       " 'from',\n",
       " 'the',\n",
       " 'education',\n",
       " 'domain',\n",
       " 'this',\n",
       " 'system',\n",
       " 'first',\n",
       " 'extracts',\n",
       " 'the',\n",
       " 'concepts',\n",
       " 'of',\n",
       " 'subjects',\n",
       " 'or',\n",
       " 'courses',\n",
       " 'and',\n",
       " 'then',\n",
       " 'identifies',\n",
       " 'the',\n",
       " 'educational',\n",
       " 'relations',\n",
       " 'between',\n",
       " 'the',\n",
       " 'concepts',\n",
       " 'More',\n",
       " 'specifically',\n",
       " 'it',\n",
       " 'adopts',\n",
       " 'the',\n",
       " 'neural',\n",
       " 'sequence',\n",
       " 'labeling',\n",
       " 'algorithm',\n",
       " 'on',\n",
       " 'pedagogical',\n",
       " 'data',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'instructional',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'employs',\n",
       " 'probabilistic',\n",
       " 'association',\n",
       " 'rule',\n",
       " 'mining',\n",
       " 'on',\n",
       " 'learning',\n",
       " 'assessment',\n",
       " 'data',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'the',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'educational',\n",
       " 'significance',\n",
       " 'We',\n",
       " 'detail',\n",
       " 'all',\n",
       " 'the',\n",
       " 'above',\n",
       " 'mentioned',\n",
       " 'efforts',\n",
       " 'through',\n",
       " 'an',\n",
       " 'exemplary',\n",
       " 'case',\n",
       " 'of',\n",
       " 'constructing',\n",
       " 'a',\n",
       " 'demonstrative',\n",
       " 'knowledge',\n",
       " 'graph',\n",
       " 'for',\n",
       " 'mathematics',\n",
       " 'where',\n",
       " 'the',\n",
       " 'instructional',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'their',\n",
       " 'prerequisite',\n",
       " 'relations',\n",
       " 'are',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'curriculum',\n",
       " 'standards',\n",
       " 'and',\n",
       " 'concept-based',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'of',\n",
       " 'students',\n",
       " 'Evaluation',\n",
       " 'results',\n",
       " 'show',\n",
       " 'that',\n",
       " 'the',\n",
       " 'F1',\n",
       " 'score',\n",
       " 'for',\n",
       " 'concept',\n",
       " 'extraction',\n",
       " 'exceeds',\n",
       " '0.',\n",
       " '70',\n",
       " 'and',\n",
       " 'for',\n",
       " 'relation',\n",
       " 'identification',\n",
       " 'the',\n",
       " 'area',\n",
       " 'under',\n",
       " 'the',\n",
       " 'curve',\n",
       " 'and',\n",
       " 'mean',\n",
       " 'average',\n",
       " 'precision',\n",
       " 'achieve',\n",
       " '0.',\n",
       " '95',\n",
       " 'and',\n",
       " '0.',\n",
       " '87',\n",
       " 'respectively']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3=text3.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace('\"','')\n",
    "Termes3 = ExpReg2.tokenize(text3)\n",
    "Termes3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4=text4.replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace('\"','')\n",
    "Termes4 = ExpReg2.tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MotsVides = nltk.corpus.stopwords.words('english')\n",
    "TermesSansMotsVides1 = [terme for terme in Termes1 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides2 = [terme for terme in Termes2 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides3 = [terme for terme in Termes3 if terme.lower() not in MotsVides]\n",
    "TermesSansMotsVides4 = [terme for terme in Termes4 if terme.lower() not in MotsVides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Porter = nltk.PorterStemmer()\n",
    "TermesNormalisation1 = [Porter.stem(terme) for terme in TermesSansMotsVides1]\n",
    "TermesNormalisation2 = [Porter.stem(terme) for terme in TermesSansMotsVides2]\n",
    "TermesNormalisation3 = [Porter.stem(terme) for terme in TermesSansMotsVides3]\n",
    "TermesNormalisation4 = [Porter.stem(terme) for terme in TermesSansMotsVides4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TermesFrequence1 = {}\n",
    "for terme in TermesNormalisation1:\n",
    "    if (terme in TermesFrequence1.keys()):\n",
    "        TermesFrequence1[terme] += 1\n",
    "    else:\n",
    "        TermesFrequence1[terme] = 1\n",
    "\n",
    "TermesFrequence2 = {}\n",
    "for terme in TermesNormalisation2:\n",
    "    if (terme in TermesFrequence2.keys()):\n",
    "        TermesFrequence2[terme] += 1\n",
    "    else:\n",
    "        TermesFrequence2[terme] = 1\n",
    "\n",
    "TermesFrequence3 = {}\n",
    "for terme in TermesNormalisation3:\n",
    "    if (terme in TermesFrequence3.keys()):\n",
    "        TermesFrequence3[terme] += 1\n",
    "    else:\n",
    "        TermesFrequence3[terme] = 1\n",
    "\n",
    "TermesFrequence4 = {}\n",
    "for terme in TermesNormalisation4:\n",
    "    if (terme in TermesFrequence4.keys()):\n",
    "        TermesFrequence4[terme] += 1\n",
    "    else:\n",
    "        TermesFrequence4[terme] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knowledg': 3,\n",
       " 'graph': 2,\n",
       " 'kg': 2,\n",
       " 'play': 1,\n",
       " 'increasingli': 1,\n",
       " 'import': 1,\n",
       " 'role': 1,\n",
       " 'recommend': 1,\n",
       " 'system': 1,\n",
       " 'recent': 1,\n",
       " 'technic': 2,\n",
       " 'trend': 1,\n",
       " 'develop': 1,\n",
       " 'end-to-end': 1,\n",
       " 'model': 6,\n",
       " 'found': 1,\n",
       " 'neural': 1,\n",
       " 'network': 2,\n",
       " 'gnn': 2,\n",
       " 'howev': 1,\n",
       " 'exist': 1,\n",
       " 'gnn-base': 1,\n",
       " 'coarse-grain': 1,\n",
       " 'relat': 7,\n",
       " 'fail': 1,\n",
       " '1': 1,\n",
       " 'identifi': 2,\n",
       " 'user-item': 2,\n",
       " 'fine-grain': 1,\n",
       " 'level': 1,\n",
       " 'intent': 7,\n",
       " '2': 1,\n",
       " 'exploit': 1,\n",
       " 'depend': 1,\n",
       " 'preserv': 1,\n",
       " 'semant': 1,\n",
       " 'long-rang': 2,\n",
       " 'connect': 2,\n",
       " 'studi': 1,\n",
       " 'explor': 1,\n",
       " 'behind': 1,\n",
       " 'interact': 1,\n",
       " 'use': 2,\n",
       " 'auxiliari': 1,\n",
       " 'item': 2,\n",
       " 'propos': 1,\n",
       " 'new': 2,\n",
       " 'graph-bas': 1,\n",
       " 'kgin': 3,\n",
       " 'attent': 1,\n",
       " 'combin': 1,\n",
       " 'encourag': 1,\n",
       " 'independ': 1,\n",
       " 'differ': 1,\n",
       " 'better': 1,\n",
       " 'capabl': 1,\n",
       " 'interpret': 2,\n",
       " 'furthermor': 1,\n",
       " 'devis': 1,\n",
       " 'inform': 2,\n",
       " 'aggreg': 1,\n",
       " 'scheme': 2,\n",
       " 'recurs': 1,\n",
       " 'integr': 1,\n",
       " 'sequenc': 1,\n",
       " 'i.e.': 1,\n",
       " 'path': 2,\n",
       " 'allow': 1,\n",
       " 'us': 1,\n",
       " 'distil': 1,\n",
       " 'user': 2,\n",
       " 'encod': 1,\n",
       " 'represent': 1,\n",
       " 'experiment': 1,\n",
       " 'result': 1,\n",
       " 'three': 1,\n",
       " 'benchmark': 1,\n",
       " 'dataset': 1,\n",
       " 'show': 2,\n",
       " 'achiev': 1,\n",
       " 'signific': 1,\n",
       " 'improv': 1,\n",
       " 'state-of-the-art': 1,\n",
       " 'method': 1,\n",
       " 'like': 1,\n",
       " 'kgat': 1,\n",
       " '41': 1,\n",
       " 'kgnn-l': 1,\n",
       " '38': 1,\n",
       " 'ckan': 1,\n",
       " '47': 1,\n",
       " 'analys': 1,\n",
       " 'offer': 1,\n",
       " 'explan': 1,\n",
       " 'predict': 1,\n",
       " 'influenti': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermesFrequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': 1,\n",
       " 'model': 2,\n",
       " 'evolut': 1,\n",
       " 'user': 2,\n",
       " 'prefer': 1,\n",
       " 'learn': 2,\n",
       " 'user-item': 2,\n",
       " 'embed': 1,\n",
       " 'base': 1,\n",
       " 'time-ord': 1,\n",
       " 'item': 3,\n",
       " 'purchas': 1,\n",
       " 'sequenc': 1,\n",
       " 'defin': 2,\n",
       " 'sequenti': 8,\n",
       " 'recommend': 3,\n",
       " 'sr': 1,\n",
       " 'problem': 1,\n",
       " 'exist': 1,\n",
       " 'method': 1,\n",
       " 'leverag': 1,\n",
       " 'pattern': 6,\n",
       " 'transit': 1,\n",
       " 'howev': 1,\n",
       " 'ignor': 1,\n",
       " 'crucial': 1,\n",
       " 'tempor': 8,\n",
       " 'collabor': 8,\n",
       " 'signal': 6,\n",
       " 'latent': 1,\n",
       " 'evolv': 1,\n",
       " 'interact': 1,\n",
       " 'coexist': 1,\n",
       " 'therefor': 1,\n",
       " 'propos': 2,\n",
       " 'unifi': 2,\n",
       " 'improv': 2,\n",
       " 'qualiti': 1,\n",
       " 'rather': 1,\n",
       " 'challeng': 1,\n",
       " 'firstli': 1,\n",
       " 'hard': 1,\n",
       " 'simultan': 2,\n",
       " 'encod': 1,\n",
       " 'secondli': 1,\n",
       " 'non-trivi': 1,\n",
       " 'express': 1,\n",
       " 'effect': 1,\n",
       " 'henc': 1,\n",
       " 'design': 1,\n",
       " 'new': 1,\n",
       " 'framework': 1,\n",
       " 'graph': 3,\n",
       " 'tgsrec': 2,\n",
       " 'upon': 1,\n",
       " 'continuous-tim': 1,\n",
       " 'bipartit': 1,\n",
       " 'novel': 2,\n",
       " 'transform': 1,\n",
       " 'tct': 3,\n",
       " 'layer': 3,\n",
       " 'advanc': 1,\n",
       " 'self-attent': 1,\n",
       " 'mechan': 1,\n",
       " 'adopt': 1,\n",
       " 'attent': 1,\n",
       " 'captur': 1,\n",
       " 'well': 1,\n",
       " 'consid': 1,\n",
       " 'dynam': 1,\n",
       " 'insid': 1,\n",
       " 'propag': 1,\n",
       " 'inform': 1,\n",
       " 'empir': 1,\n",
       " 'result': 1,\n",
       " 'five': 1,\n",
       " 'dataset': 1,\n",
       " 'show': 1,\n",
       " 'modelnam': 1,\n",
       " 'significantli': 1,\n",
       " 'outperform': 1,\n",
       " 'baselin': 1,\n",
       " 'averag': 1,\n",
       " '22.5%': 1,\n",
       " '22.1%': 1,\n",
       " 'absolut': 1,\n",
       " 'recal': 1,\n",
       " '10': 1,\n",
       " 'mrr': 1,\n",
       " 'respect': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermesFrequence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'motiv': 1,\n",
       " 'vast': 1,\n",
       " 'applic': 1,\n",
       " 'knowledg': 3,\n",
       " 'graph': 3,\n",
       " 'increas': 1,\n",
       " 'demand': 1,\n",
       " 'educ': 5,\n",
       " 'domain': 2,\n",
       " 'propos': 1,\n",
       " 'system': 2,\n",
       " 'call': 1,\n",
       " 'knowedu': 1,\n",
       " 'automat': 1,\n",
       " 'construct': 2,\n",
       " 'leverag': 1,\n",
       " 'heterogen': 1,\n",
       " 'data': 6,\n",
       " 'e.g.': 1,\n",
       " 'pedagog': 2,\n",
       " 'learn': 2,\n",
       " 'assess': 2,\n",
       " 'first': 1,\n",
       " 'extract': 3,\n",
       " 'concept': 5,\n",
       " 'subject': 1,\n",
       " 'cours': 1,\n",
       " 'identifi': 2,\n",
       " 'relat': 4,\n",
       " 'specif': 1,\n",
       " 'adopt': 1,\n",
       " 'neural': 1,\n",
       " 'sequenc': 1,\n",
       " 'label': 1,\n",
       " 'algorithm': 1,\n",
       " 'instruct': 2,\n",
       " 'employ': 1,\n",
       " 'probabilist': 1,\n",
       " 'associ': 1,\n",
       " 'rule': 1,\n",
       " 'mine': 1,\n",
       " 'signific': 1,\n",
       " 'detail': 1,\n",
       " 'mention': 1,\n",
       " 'effort': 1,\n",
       " 'exemplari': 1,\n",
       " 'case': 1,\n",
       " 'demonstr': 1,\n",
       " 'mathemat': 1,\n",
       " 'prerequisit': 1,\n",
       " 'deriv': 1,\n",
       " 'curriculum': 1,\n",
       " 'standard': 1,\n",
       " 'concept-bas': 1,\n",
       " 'perform': 1,\n",
       " 'student': 1,\n",
       " 'evalu': 1,\n",
       " 'result': 1,\n",
       " 'show': 1,\n",
       " 'f1': 1,\n",
       " 'score': 1,\n",
       " 'exce': 1,\n",
       " '0.': 3,\n",
       " '70': 1,\n",
       " 'identif': 1,\n",
       " 'area': 1,\n",
       " 'curv': 1,\n",
       " 'mean': 1,\n",
       " 'averag': 1,\n",
       " 'precis': 1,\n",
       " 'achiev': 1,\n",
       " '95': 1,\n",
       " '87': 1,\n",
       " 'respect': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermesFrequence3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knowledg': 3,\n",
       " 'graph': 3,\n",
       " 'kg': 4,\n",
       " 'contain': 1,\n",
       " 'well-structur': 1,\n",
       " 'extern': 1,\n",
       " 'inform': 4,\n",
       " 'shown': 1,\n",
       " 'effect': 1,\n",
       " 'high-qual': 1,\n",
       " 'recommend': 4,\n",
       " 'howev': 1,\n",
       " 'exist': 1,\n",
       " 'enhanc': 2,\n",
       " 'method': 4,\n",
       " 'larg': 1,\n",
       " 'focus': 1,\n",
       " 'explor': 1,\n",
       " 'advanc': 1,\n",
       " 'neural': 2,\n",
       " 'network': 2,\n",
       " 'architectur': 1,\n",
       " 'better': 2,\n",
       " 'investig': 1,\n",
       " 'structur': 1,\n",
       " 'model': 5,\n",
       " 'learn': 5,\n",
       " 'mainli': 1,\n",
       " 'reli': 1,\n",
       " 'neg': 2,\n",
       " 'sampl': 2,\n",
       " 'ns': 3,\n",
       " 'optim': 2,\n",
       " 'embed': 2,\n",
       " 'task': 2,\n",
       " 'sinc': 1,\n",
       " 'robust': 1,\n",
       " 'e.g.': 1,\n",
       " 'small': 1,\n",
       " 'fraction': 1,\n",
       " 'instanc': 1,\n",
       " 'may': 1,\n",
       " 'lose': 1,\n",
       " 'lot': 1,\n",
       " 'use': 1,\n",
       " 'reason': 1,\n",
       " 'argu': 1,\n",
       " 'insuffici': 1,\n",
       " 'captur': 1,\n",
       " 'collabor': 1,\n",
       " 'among': 2,\n",
       " 'user': 3,\n",
       " 'item': 3,\n",
       " 'entiti': 2,\n",
       " 'paper': 1,\n",
       " 'propos': 2,\n",
       " 'novel': 2,\n",
       " 'jointli': 1,\n",
       " 'non-sampl': 1,\n",
       " 'jnskr': 4,\n",
       " 'specif': 1,\n",
       " 'first': 1,\n",
       " 'design': 2,\n",
       " 'new': 1,\n",
       " 'effici': 3,\n",
       " 'algorithm': 1,\n",
       " 'subgraph': 1,\n",
       " 'encod': 1,\n",
       " 'attent': 1,\n",
       " 'character': 1,\n",
       " 'prefer': 1,\n",
       " 'memor': 1,\n",
       " 'strategi': 1,\n",
       " 'joint': 1,\n",
       " 'framework': 1,\n",
       " 'fine-grain': 1,\n",
       " 'connect': 1,\n",
       " 'also': 2,\n",
       " 'paramet': 1,\n",
       " 'whole': 1,\n",
       " 'train': 2,\n",
       " 'data': 2,\n",
       " 'includ': 1,\n",
       " 'non-observ': 1,\n",
       " 'rather': 1,\n",
       " 'low': 1,\n",
       " 'time': 2,\n",
       " 'complex': 1,\n",
       " 'experiment': 1,\n",
       " 'result': 1,\n",
       " 'two': 1,\n",
       " 'public': 1,\n",
       " 'benchmark': 1,\n",
       " 'show': 2,\n",
       " 'significantli': 1,\n",
       " 'outperform': 1,\n",
       " 'state-of-the-art': 1,\n",
       " 'like': 1,\n",
       " 'ripplenet': 1,\n",
       " 'kgat': 2,\n",
       " 'remark': 1,\n",
       " 'signific': 1,\n",
       " 'advantag': 1,\n",
       " '20': 1,\n",
       " 'faster': 1,\n",
       " 'make': 1,\n",
       " 'applic': 1,\n",
       " 'real-world': 1,\n",
       " 'large-scal': 1,\n",
       " 'system': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermesFrequence4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('knowledg', 1): 3,\n",
       " ('graph', 1): 2,\n",
       " ('kg', 1): 2,\n",
       " ('play', 1): 1,\n",
       " ('increasingli', 1): 1,\n",
       " ('import', 1): 1,\n",
       " ('role', 1): 1,\n",
       " ('recommend', 1): 1,\n",
       " ('system', 1): 1,\n",
       " ('recent', 1): 1,\n",
       " ('technic', 1): 2,\n",
       " ('trend', 1): 1,\n",
       " ('develop', 1): 1,\n",
       " ('end-to-end', 1): 1,\n",
       " ('model', 1): 6,\n",
       " ('found', 1): 1,\n",
       " ('neural', 1): 1,\n",
       " ('network', 1): 2,\n",
       " ('gnn', 1): 2,\n",
       " ('howev', 1): 1,\n",
       " ('exist', 1): 1,\n",
       " ('gnn-base', 1): 1,\n",
       " ('coarse-grain', 1): 1,\n",
       " ('relat', 1): 7,\n",
       " ('fail', 1): 1,\n",
       " ('1', 1): 1,\n",
       " ('identifi', 1): 2,\n",
       " ('user-item', 1): 2,\n",
       " ('fine-grain', 1): 1,\n",
       " ('level', 1): 1,\n",
       " ('intent', 1): 7,\n",
       " ('2', 1): 1,\n",
       " ('exploit', 1): 1,\n",
       " ('depend', 1): 1,\n",
       " ('preserv', 1): 1,\n",
       " ('semant', 1): 1,\n",
       " ('long-rang', 1): 2,\n",
       " ('connect', 1): 2,\n",
       " ('studi', 1): 1,\n",
       " ('explor', 1): 1,\n",
       " ('behind', 1): 1,\n",
       " ('interact', 1): 1,\n",
       " ('use', 1): 2,\n",
       " ('auxiliari', 1): 1,\n",
       " ('item', 1): 2,\n",
       " ('propos', 1): 1,\n",
       " ('new', 1): 2,\n",
       " ('graph-bas', 1): 1,\n",
       " ('kgin', 1): 3,\n",
       " ('attent', 1): 1,\n",
       " ('combin', 1): 1,\n",
       " ('encourag', 1): 1,\n",
       " ('independ', 1): 1,\n",
       " ('differ', 1): 1,\n",
       " ('better', 1): 1,\n",
       " ('capabl', 1): 1,\n",
       " ('interpret', 1): 2,\n",
       " ('furthermor', 1): 1,\n",
       " ('devis', 1): 1,\n",
       " ('inform', 1): 2,\n",
       " ('aggreg', 1): 1,\n",
       " ('scheme', 1): 2,\n",
       " ('recurs', 1): 1,\n",
       " ('integr', 1): 1,\n",
       " ('sequenc', 1): 1,\n",
       " ('i.e.', 1): 1,\n",
       " ('path', 1): 2,\n",
       " ('allow', 1): 1,\n",
       " ('us', 1): 1,\n",
       " ('distil', 1): 1,\n",
       " ('user', 1): 2,\n",
       " ('encod', 1): 1,\n",
       " ('represent', 1): 1,\n",
       " ('experiment', 1): 1,\n",
       " ('result', 1): 1,\n",
       " ('three', 1): 1,\n",
       " ('benchmark', 1): 1,\n",
       " ('dataset', 1): 1,\n",
       " ('show', 1): 2,\n",
       " ('achiev', 1): 1,\n",
       " ('signific', 1): 1,\n",
       " ('improv', 1): 1,\n",
       " ('state-of-the-art', 1): 1,\n",
       " ('method', 1): 1,\n",
       " ('like', 1): 1,\n",
       " ('kgat', 1): 1,\n",
       " ('41', 1): 1,\n",
       " ('kgnn-l', 1): 1,\n",
       " ('38', 1): 1,\n",
       " ('ckan', 1): 1,\n",
       " ('47', 1): 1,\n",
       " ('analys', 1): 1,\n",
       " ('offer', 1): 1,\n",
       " ('explan', 1): 1,\n",
       " ('predict', 1): 1,\n",
       " ('influenti', 1): 1,\n",
       " ('order', 1): 0,\n",
       " ('evolut', 1): 0,\n",
       " ('prefer', 1): 0,\n",
       " ('learn', 1): 0,\n",
       " ('embed', 1): 0,\n",
       " ('base', 1): 0,\n",
       " ('time-ord', 1): 0,\n",
       " ('purchas', 1): 0,\n",
       " ('defin', 1): 0,\n",
       " ('sequenti', 1): 0,\n",
       " ('sr', 1): 0,\n",
       " ('problem', 1): 0,\n",
       " ('leverag', 1): 0,\n",
       " ('pattern', 1): 0,\n",
       " ('transit', 1): 0,\n",
       " ('ignor', 1): 0,\n",
       " ('crucial', 1): 0,\n",
       " ('tempor', 1): 0,\n",
       " ('collabor', 1): 0,\n",
       " ('signal', 1): 0,\n",
       " ('latent', 1): 0,\n",
       " ('evolv', 1): 0,\n",
       " ('coexist', 1): 0,\n",
       " ('therefor', 1): 0,\n",
       " ('unifi', 1): 0,\n",
       " ('qualiti', 1): 0,\n",
       " ('rather', 1): 0,\n",
       " ('challeng', 1): 0,\n",
       " ('firstli', 1): 0,\n",
       " ('hard', 1): 0,\n",
       " ('simultan', 1): 0,\n",
       " ('secondli', 1): 0,\n",
       " ('non-trivi', 1): 0,\n",
       " ('express', 1): 0,\n",
       " ('effect', 1): 0,\n",
       " ('henc', 1): 0,\n",
       " ('design', 1): 0,\n",
       " ('framework', 1): 0,\n",
       " ('tgsrec', 1): 0,\n",
       " ('upon', 1): 0,\n",
       " ('continuous-tim', 1): 0,\n",
       " ('bipartit', 1): 0,\n",
       " ('novel', 1): 0,\n",
       " ('transform', 1): 0,\n",
       " ('tct', 1): 0,\n",
       " ('layer', 1): 0,\n",
       " ('advanc', 1): 0,\n",
       " ('self-attent', 1): 0,\n",
       " ('mechan', 1): 0,\n",
       " ('adopt', 1): 0,\n",
       " ('captur', 1): 0,\n",
       " ('well', 1): 0,\n",
       " ('consid', 1): 0,\n",
       " ('dynam', 1): 0,\n",
       " ('insid', 1): 0,\n",
       " ('propag', 1): 0,\n",
       " ('empir', 1): 0,\n",
       " ('five', 1): 0,\n",
       " ('modelnam', 1): 0,\n",
       " ('significantli', 1): 0,\n",
       " ('outperform', 1): 0,\n",
       " ('baselin', 1): 0,\n",
       " ('averag', 1): 0,\n",
       " ('22.5%', 1): 0,\n",
       " ('22.1%', 1): 0,\n",
       " ('absolut', 1): 0,\n",
       " ('recal', 1): 0,\n",
       " ('10', 1): 0,\n",
       " ('mrr', 1): 0,\n",
       " ('respect', 1): 0,\n",
       " ('motiv', 1): 0,\n",
       " ('vast', 1): 0,\n",
       " ('applic', 1): 0,\n",
       " ('increas', 1): 0,\n",
       " ('demand', 1): 0,\n",
       " ('educ', 1): 0,\n",
       " ('domain', 1): 0,\n",
       " ('call', 1): 0,\n",
       " ('knowedu', 1): 0,\n",
       " ('automat', 1): 0,\n",
       " ('construct', 1): 0,\n",
       " ('heterogen', 1): 0,\n",
       " ('data', 1): 0,\n",
       " ('e.g.', 1): 0,\n",
       " ('pedagog', 1): 0,\n",
       " ('assess', 1): 0,\n",
       " ('first', 1): 0,\n",
       " ('extract', 1): 0,\n",
       " ('concept', 1): 0,\n",
       " ('subject', 1): 0,\n",
       " ('cours', 1): 0,\n",
       " ('specif', 1): 0,\n",
       " ('label', 1): 0,\n",
       " ('algorithm', 1): 0,\n",
       " ('instruct', 1): 0,\n",
       " ('employ', 1): 0,\n",
       " ('probabilist', 1): 0,\n",
       " ('associ', 1): 0,\n",
       " ('rule', 1): 0,\n",
       " ('mine', 1): 0,\n",
       " ('detail', 1): 0,\n",
       " ('mention', 1): 0,\n",
       " ('effort', 1): 0,\n",
       " ('exemplari', 1): 0,\n",
       " ('case', 1): 0,\n",
       " ('demonstr', 1): 0,\n",
       " ('mathemat', 1): 0,\n",
       " ('prerequisit', 1): 0,\n",
       " ('deriv', 1): 0,\n",
       " ('curriculum', 1): 0,\n",
       " ('standard', 1): 0,\n",
       " ('concept-bas', 1): 0,\n",
       " ('perform', 1): 0,\n",
       " ('student', 1): 0,\n",
       " ('evalu', 1): 0,\n",
       " ('f1', 1): 0,\n",
       " ('score', 1): 0,\n",
       " ('exce', 1): 0,\n",
       " ('0.', 1): 0,\n",
       " ('70', 1): 0,\n",
       " ('identif', 1): 0,\n",
       " ('area', 1): 0,\n",
       " ('curv', 1): 0,\n",
       " ('mean', 1): 0,\n",
       " ('precis', 1): 0,\n",
       " ('95', 1): 0,\n",
       " ('87', 1): 0,\n",
       " ('contain', 1): 0,\n",
       " ('well-structur', 1): 0,\n",
       " ('extern', 1): 0,\n",
       " ('shown', 1): 0,\n",
       " ('high-qual', 1): 0,\n",
       " ('enhanc', 1): 0,\n",
       " ('larg', 1): 0,\n",
       " ('focus', 1): 0,\n",
       " ('architectur', 1): 0,\n",
       " ('investig', 1): 0,\n",
       " ('structur', 1): 0,\n",
       " ('mainli', 1): 0,\n",
       " ('reli', 1): 0,\n",
       " ('neg', 1): 0,\n",
       " ('sampl', 1): 0,\n",
       " ('ns', 1): 0,\n",
       " ('optim', 1): 0,\n",
       " ('task', 1): 0,\n",
       " ('sinc', 1): 0,\n",
       " ('robust', 1): 0,\n",
       " ('small', 1): 0,\n",
       " ('fraction', 1): 0,\n",
       " ('instanc', 1): 0,\n",
       " ('may', 1): 0,\n",
       " ('lose', 1): 0,\n",
       " ('lot', 1): 0,\n",
       " ('reason', 1): 0,\n",
       " ('argu', 1): 0,\n",
       " ('insuffici', 1): 0,\n",
       " ('among', 1): 0,\n",
       " ('entiti', 1): 0,\n",
       " ('paper', 1): 0,\n",
       " ('jointli', 1): 0,\n",
       " ('non-sampl', 1): 0,\n",
       " ('jnskr', 1): 0,\n",
       " ('effici', 1): 0,\n",
       " ('subgraph', 1): 0,\n",
       " ('character', 1): 0,\n",
       " ('memor', 1): 0,\n",
       " ('strategi', 1): 0,\n",
       " ('joint', 1): 0,\n",
       " ('also', 1): 0,\n",
       " ('paramet', 1): 0,\n",
       " ('whole', 1): 0,\n",
       " ('train', 1): 0,\n",
       " ('includ', 1): 0,\n",
       " ('non-observ', 1): 0,\n",
       " ('low', 1): 0,\n",
       " ('time', 1): 0,\n",
       " ('complex', 1): 0,\n",
       " ('two', 1): 0,\n",
       " ('public', 1): 0,\n",
       " ('ripplenet', 1): 0,\n",
       " ('remark', 1): 0,\n",
       " ('advantag', 1): 0,\n",
       " ('20', 1): 0,\n",
       " ('faster', 1): 0,\n",
       " ('make', 1): 0,\n",
       " ('real-world', 1): 0,\n",
       " ('large-scal', 1): 0,\n",
       " ('order', 2): 1,\n",
       " ('model', 2): 2,\n",
       " ('evolut', 2): 1,\n",
       " ('user', 2): 2,\n",
       " ('prefer', 2): 1,\n",
       " ('learn', 2): 2,\n",
       " ('user-item', 2): 2,\n",
       " ('embed', 2): 1,\n",
       " ('base', 2): 1,\n",
       " ('time-ord', 2): 1,\n",
       " ('item', 2): 3,\n",
       " ('purchas', 2): 1,\n",
       " ('sequenc', 2): 1,\n",
       " ('defin', 2): 2,\n",
       " ('sequenti', 2): 8,\n",
       " ('recommend', 2): 3,\n",
       " ('sr', 2): 1,\n",
       " ('problem', 2): 1,\n",
       " ('exist', 2): 1,\n",
       " ('method', 2): 1,\n",
       " ('leverag', 2): 1,\n",
       " ('pattern', 2): 6,\n",
       " ('transit', 2): 1,\n",
       " ('howev', 2): 1,\n",
       " ('ignor', 2): 1,\n",
       " ('crucial', 2): 1,\n",
       " ('tempor', 2): 8,\n",
       " ('collabor', 2): 8,\n",
       " ('signal', 2): 6,\n",
       " ('latent', 2): 1,\n",
       " ('evolv', 2): 1,\n",
       " ('interact', 2): 1,\n",
       " ('coexist', 2): 1,\n",
       " ('therefor', 2): 1,\n",
       " ('propos', 2): 2,\n",
       " ('unifi', 2): 2,\n",
       " ('improv', 2): 2,\n",
       " ('qualiti', 2): 1,\n",
       " ('rather', 2): 1,\n",
       " ('challeng', 2): 1,\n",
       " ('firstli', 2): 1,\n",
       " ('hard', 2): 1,\n",
       " ('simultan', 2): 2,\n",
       " ('encod', 2): 1,\n",
       " ('secondli', 2): 1,\n",
       " ('non-trivi', 2): 1,\n",
       " ('express', 2): 1,\n",
       " ('effect', 2): 1,\n",
       " ('henc', 2): 1,\n",
       " ('design', 2): 1,\n",
       " ('new', 2): 1,\n",
       " ('framework', 2): 1,\n",
       " ('graph', 2): 3,\n",
       " ('tgsrec', 2): 2,\n",
       " ('upon', 2): 1,\n",
       " ('continuous-tim', 2): 1,\n",
       " ('bipartit', 2): 1,\n",
       " ('novel', 2): 2,\n",
       " ('transform', 2): 1,\n",
       " ('tct', 2): 3,\n",
       " ('layer', 2): 3,\n",
       " ('advanc', 2): 1,\n",
       " ('self-attent', 2): 1,\n",
       " ('mechan', 2): 1,\n",
       " ('adopt', 2): 1,\n",
       " ('attent', 2): 1,\n",
       " ('captur', 2): 1,\n",
       " ('well', 2): 1,\n",
       " ('consid', 2): 1,\n",
       " ('dynam', 2): 1,\n",
       " ('insid', 2): 1,\n",
       " ('propag', 2): 1,\n",
       " ('inform', 2): 1,\n",
       " ('empir', 2): 1,\n",
       " ('result', 2): 1,\n",
       " ('five', 2): 1,\n",
       " ('dataset', 2): 1,\n",
       " ('show', 2): 1,\n",
       " ('modelnam', 2): 1,\n",
       " ('significantli', 2): 1,\n",
       " ('outperform', 2): 1,\n",
       " ('baselin', 2): 1,\n",
       " ('averag', 2): 1,\n",
       " ('22.5%', 2): 1,\n",
       " ('22.1%', 2): 1,\n",
       " ('absolut', 2): 1,\n",
       " ('recal', 2): 1,\n",
       " ('10', 2): 1,\n",
       " ('mrr', 2): 1,\n",
       " ('respect', 2): 1,\n",
       " ('knowledg', 2): 0,\n",
       " ('kg', 2): 0,\n",
       " ('play', 2): 0,\n",
       " ('increasingli', 2): 0,\n",
       " ('import', 2): 0,\n",
       " ('role', 2): 0,\n",
       " ('system', 2): 0,\n",
       " ('recent', 2): 0,\n",
       " ('technic', 2): 0,\n",
       " ('trend', 2): 0,\n",
       " ('develop', 2): 0,\n",
       " ('end-to-end', 2): 0,\n",
       " ('found', 2): 0,\n",
       " ('neural', 2): 0,\n",
       " ('network', 2): 0,\n",
       " ('gnn', 2): 0,\n",
       " ('gnn-base', 2): 0,\n",
       " ('coarse-grain', 2): 0,\n",
       " ('relat', 2): 0,\n",
       " ('fail', 2): 0,\n",
       " ('1', 2): 0,\n",
       " ('identifi', 2): 0,\n",
       " ('fine-grain', 2): 0,\n",
       " ('level', 2): 0,\n",
       " ('intent', 2): 0,\n",
       " ('2', 2): 0,\n",
       " ('exploit', 2): 0,\n",
       " ('depend', 2): 0,\n",
       " ('preserv', 2): 0,\n",
       " ('semant', 2): 0,\n",
       " ('long-rang', 2): 0,\n",
       " ('connect', 2): 0,\n",
       " ('studi', 2): 0,\n",
       " ('explor', 2): 0,\n",
       " ('behind', 2): 0,\n",
       " ('use', 2): 0,\n",
       " ('auxiliari', 2): 0,\n",
       " ('graph-bas', 2): 0,\n",
       " ('kgin', 2): 0,\n",
       " ('combin', 2): 0,\n",
       " ('encourag', 2): 0,\n",
       " ('independ', 2): 0,\n",
       " ('differ', 2): 0,\n",
       " ('better', 2): 0,\n",
       " ('capabl', 2): 0,\n",
       " ('interpret', 2): 0,\n",
       " ('furthermor', 2): 0,\n",
       " ('devis', 2): 0,\n",
       " ('aggreg', 2): 0,\n",
       " ('scheme', 2): 0,\n",
       " ('recurs', 2): 0,\n",
       " ('integr', 2): 0,\n",
       " ('i.e.', 2): 0,\n",
       " ('path', 2): 0,\n",
       " ('allow', 2): 0,\n",
       " ('us', 2): 0,\n",
       " ('distil', 2): 0,\n",
       " ('represent', 2): 0,\n",
       " ('experiment', 2): 0,\n",
       " ('three', 2): 0,\n",
       " ('benchmark', 2): 0,\n",
       " ('achiev', 2): 0,\n",
       " ('signific', 2): 0,\n",
       " ('state-of-the-art', 2): 0,\n",
       " ('like', 2): 0,\n",
       " ('kgat', 2): 0,\n",
       " ('41', 2): 0,\n",
       " ('kgnn-l', 2): 0,\n",
       " ('38', 2): 0,\n",
       " ('ckan', 2): 0,\n",
       " ('47', 2): 0,\n",
       " ('analys', 2): 0,\n",
       " ('offer', 2): 0,\n",
       " ('explan', 2): 0,\n",
       " ('predict', 2): 0,\n",
       " ('influenti', 2): 0,\n",
       " ('motiv', 2): 0,\n",
       " ('vast', 2): 0,\n",
       " ('applic', 2): 0,\n",
       " ('increas', 2): 0,\n",
       " ('demand', 2): 0,\n",
       " ('educ', 2): 0,\n",
       " ('domain', 2): 0,\n",
       " ('call', 2): 0,\n",
       " ('knowedu', 2): 0,\n",
       " ('automat', 2): 0,\n",
       " ('construct', 2): 0,\n",
       " ('heterogen', 2): 0,\n",
       " ('data', 2): 0,\n",
       " ('e.g.', 2): 0,\n",
       " ('pedagog', 2): 0,\n",
       " ('assess', 2): 0,\n",
       " ('first', 2): 0,\n",
       " ('extract', 2): 0,\n",
       " ('concept', 2): 0,\n",
       " ('subject', 2): 0,\n",
       " ('cours', 2): 0,\n",
       " ('specif', 2): 0,\n",
       " ('label', 2): 0,\n",
       " ('algorithm', 2): 0,\n",
       " ('instruct', 2): 0,\n",
       " ('employ', 2): 0,\n",
       " ('probabilist', 2): 0,\n",
       " ('associ', 2): 0,\n",
       " ('rule', 2): 0,\n",
       " ('mine', 2): 0,\n",
       " ('detail', 2): 0,\n",
       " ('mention', 2): 0,\n",
       " ('effort', 2): 0,\n",
       " ('exemplari', 2): 0,\n",
       " ('case', 2): 0,\n",
       " ('demonstr', 2): 0,\n",
       " ('mathemat', 2): 0,\n",
       " ('prerequisit', 2): 0,\n",
       " ('deriv', 2): 0,\n",
       " ('curriculum', 2): 0,\n",
       " ('standard', 2): 0,\n",
       " ('concept-bas', 2): 0,\n",
       " ('perform', 2): 0,\n",
       " ('student', 2): 0,\n",
       " ('evalu', 2): 0,\n",
       " ('f1', 2): 0,\n",
       " ('score', 2): 0,\n",
       " ('exce', 2): 0,\n",
       " ('0.', 2): 0,\n",
       " ('70', 2): 0,\n",
       " ('identif', 2): 0,\n",
       " ('area', 2): 0,\n",
       " ('curv', 2): 0,\n",
       " ('mean', 2): 0,\n",
       " ('precis', 2): 0,\n",
       " ('95', 2): 0,\n",
       " ('87', 2): 0,\n",
       " ('contain', 2): 0,\n",
       " ('well-structur', 2): 0,\n",
       " ('extern', 2): 0,\n",
       " ('shown', 2): 0,\n",
       " ('high-qual', 2): 0,\n",
       " ('enhanc', 2): 0,\n",
       " ('larg', 2): 0,\n",
       " ('focus', 2): 0,\n",
       " ('architectur', 2): 0,\n",
       " ('investig', 2): 0,\n",
       " ('structur', 2): 0,\n",
       " ('mainli', 2): 0,\n",
       " ('reli', 2): 0,\n",
       " ('neg', 2): 0,\n",
       " ('sampl', 2): 0,\n",
       " ('ns', 2): 0,\n",
       " ('optim', 2): 0,\n",
       " ('task', 2): 0,\n",
       " ('sinc', 2): 0,\n",
       " ('robust', 2): 0,\n",
       " ('small', 2): 0,\n",
       " ('fraction', 2): 0,\n",
       " ('instanc', 2): 0,\n",
       " ('may', 2): 0,\n",
       " ('lose', 2): 0,\n",
       " ('lot', 2): 0,\n",
       " ('reason', 2): 0,\n",
       " ('argu', 2): 0,\n",
       " ('insuffici', 2): 0,\n",
       " ('among', 2): 0,\n",
       " ('entiti', 2): 0,\n",
       " ('paper', 2): 0,\n",
       " ('jointli', 2): 0,\n",
       " ('non-sampl', 2): 0,\n",
       " ('jnskr', 2): 0,\n",
       " ('effici', 2): 0,\n",
       " ('subgraph', 2): 0,\n",
       " ('character', 2): 0,\n",
       " ('memor', 2): 0,\n",
       " ('strategi', 2): 0,\n",
       " ('joint', 2): 0,\n",
       " ('also', 2): 0,\n",
       " ('paramet', 2): 0,\n",
       " ('whole', 2): 0,\n",
       " ('train', 2): 0,\n",
       " ('includ', 2): 0,\n",
       " ('non-observ', 2): 0,\n",
       " ('low', 2): 0,\n",
       " ('time', 2): 0,\n",
       " ('complex', 2): 0,\n",
       " ('two', 2): 0,\n",
       " ('public', 2): 0,\n",
       " ('ripplenet', 2): 0,\n",
       " ('remark', 2): 0,\n",
       " ('advantag', 2): 0,\n",
       " ('20', 2): 0,\n",
       " ('faster', 2): 0,\n",
       " ('make', 2): 0,\n",
       " ('real-world', 2): 0,\n",
       " ('large-scal', 2): 0,\n",
       " ('motiv', 3): 1,\n",
       " ('vast', 3): 1,\n",
       " ('applic', 3): 1,\n",
       " ('knowledg', 3): 3,\n",
       " ('graph', 3): 3,\n",
       " ('increas', 3): 1,\n",
       " ('demand', 3): 1,\n",
       " ('educ', 3): 5,\n",
       " ('domain', 3): 2,\n",
       " ('propos', 3): 1,\n",
       " ('system', 3): 2,\n",
       " ('call', 3): 1,\n",
       " ('knowedu', 3): 1,\n",
       " ('automat', 3): 1,\n",
       " ('construct', 3): 2,\n",
       " ('leverag', 3): 1,\n",
       " ('heterogen', 3): 1,\n",
       " ('data', 3): 6,\n",
       " ('e.g.', 3): 1,\n",
       " ('pedagog', 3): 2,\n",
       " ('learn', 3): 2,\n",
       " ('assess', 3): 2,\n",
       " ('first', 3): 1,\n",
       " ('extract', 3): 3,\n",
       " ('concept', 3): 5,\n",
       " ('subject', 3): 1,\n",
       " ('cours', 3): 1,\n",
       " ('identifi', 3): 2,\n",
       " ('relat', 3): 4,\n",
       " ('specif', 3): 1,\n",
       " ('adopt', 3): 1,\n",
       " ('neural', 3): 1,\n",
       " ('sequenc', 3): 1,\n",
       " ('label', 3): 1,\n",
       " ('algorithm', 3): 1,\n",
       " ('instruct', 3): 2,\n",
       " ('employ', 3): 1,\n",
       " ('probabilist', 3): 1,\n",
       " ('associ', 3): 1,\n",
       " ('rule', 3): 1,\n",
       " ('mine', 3): 1,\n",
       " ('signific', 3): 1,\n",
       " ('detail', 3): 1,\n",
       " ('mention', 3): 1,\n",
       " ('effort', 3): 1,\n",
       " ('exemplari', 3): 1,\n",
       " ('case', 3): 1,\n",
       " ('demonstr', 3): 1,\n",
       " ('mathemat', 3): 1,\n",
       " ('prerequisit', 3): 1,\n",
       " ('deriv', 3): 1,\n",
       " ('curriculum', 3): 1,\n",
       " ('standard', 3): 1,\n",
       " ('concept-bas', 3): 1,\n",
       " ('perform', 3): 1,\n",
       " ('student', 3): 1,\n",
       " ('evalu', 3): 1,\n",
       " ('result', 3): 1,\n",
       " ('show', 3): 1,\n",
       " ('f1', 3): 1,\n",
       " ('score', 3): 1,\n",
       " ('exce', 3): 1,\n",
       " ('0.', 3): 3,\n",
       " ('70', 3): 1,\n",
       " ('identif', 3): 1,\n",
       " ('area', 3): 1,\n",
       " ('curv', 3): 1,\n",
       " ('mean', 3): 1,\n",
       " ('averag', 3): 1,\n",
       " ('precis', 3): 1,\n",
       " ('achiev', 3): 1,\n",
       " ('95', 3): 1,\n",
       " ('87', 3): 1,\n",
       " ('respect', 3): 1,\n",
       " ('kg', 3): 0,\n",
       " ('play', 3): 0,\n",
       " ('increasingli', 3): 0,\n",
       " ('import', 3): 0,\n",
       " ('role', 3): 0,\n",
       " ('recommend', 3): 0,\n",
       " ('recent', 3): 0,\n",
       " ('technic', 3): 0,\n",
       " ('trend', 3): 0,\n",
       " ('develop', 3): 0,\n",
       " ('end-to-end', 3): 0,\n",
       " ('model', 3): 0,\n",
       " ('found', 3): 0,\n",
       " ('network', 3): 0,\n",
       " ('gnn', 3): 0,\n",
       " ('howev', 3): 0,\n",
       " ('exist', 3): 0,\n",
       " ('gnn-base', 3): 0,\n",
       " ('coarse-grain', 3): 0,\n",
       " ('fail', 3): 0,\n",
       " ('1', 3): 0,\n",
       " ('user-item', 3): 0,\n",
       " ('fine-grain', 3): 0,\n",
       " ('level', 3): 0,\n",
       " ('intent', 3): 0,\n",
       " ('2', 3): 0,\n",
       " ('exploit', 3): 0,\n",
       " ('depend', 3): 0,\n",
       " ('preserv', 3): 0,\n",
       " ('semant', 3): 0,\n",
       " ('long-rang', 3): 0,\n",
       " ('connect', 3): 0,\n",
       " ('studi', 3): 0,\n",
       " ('explor', 3): 0,\n",
       " ('behind', 3): 0,\n",
       " ('interact', 3): 0,\n",
       " ('use', 3): 0,\n",
       " ('auxiliari', 3): 0,\n",
       " ('item', 3): 0,\n",
       " ('new', 3): 0,\n",
       " ('graph-bas', 3): 0,\n",
       " ('kgin', 3): 0,\n",
       " ('attent', 3): 0,\n",
       " ('combin', 3): 0,\n",
       " ('encourag', 3): 0,\n",
       " ('independ', 3): 0,\n",
       " ('differ', 3): 0,\n",
       " ('better', 3): 0,\n",
       " ('capabl', 3): 0,\n",
       " ('interpret', 3): 0,\n",
       " ('furthermor', 3): 0,\n",
       " ('devis', 3): 0,\n",
       " ('inform', 3): 0,\n",
       " ('aggreg', 3): 0,\n",
       " ('scheme', 3): 0,\n",
       " ('recurs', 3): 0,\n",
       " ('integr', 3): 0,\n",
       " ('i.e.', 3): 0,\n",
       " ('path', 3): 0,\n",
       " ('allow', 3): 0,\n",
       " ('us', 3): 0,\n",
       " ('distil', 3): 0,\n",
       " ('user', 3): 0,\n",
       " ('encod', 3): 0,\n",
       " ('represent', 3): 0,\n",
       " ('experiment', 3): 0,\n",
       " ('three', 3): 0,\n",
       " ('benchmark', 3): 0,\n",
       " ('dataset', 3): 0,\n",
       " ('improv', 3): 0,\n",
       " ('state-of-the-art', 3): 0,\n",
       " ('method', 3): 0,\n",
       " ('like', 3): 0,\n",
       " ('kgat', 3): 0,\n",
       " ('41', 3): 0,\n",
       " ('kgnn-l', 3): 0,\n",
       " ('38', 3): 0,\n",
       " ('ckan', 3): 0,\n",
       " ('47', 3): 0,\n",
       " ('analys', 3): 0,\n",
       " ('offer', 3): 0,\n",
       " ('explan', 3): 0,\n",
       " ('predict', 3): 0,\n",
       " ('influenti', 3): 0,\n",
       " ('order', 3): 0,\n",
       " ('evolut', 3): 0,\n",
       " ('prefer', 3): 0,\n",
       " ('embed', 3): 0,\n",
       " ('base', 3): 0,\n",
       " ('time-ord', 3): 0,\n",
       " ('purchas', 3): 0,\n",
       " ('defin', 3): 0,\n",
       " ('sequenti', 3): 0,\n",
       " ('sr', 3): 0,\n",
       " ('problem', 3): 0,\n",
       " ('pattern', 3): 0,\n",
       " ('transit', 3): 0,\n",
       " ('ignor', 3): 0,\n",
       " ('crucial', 3): 0,\n",
       " ('tempor', 3): 0,\n",
       " ('collabor', 3): 0,\n",
       " ('signal', 3): 0,\n",
       " ('latent', 3): 0,\n",
       " ('evolv', 3): 0,\n",
       " ('coexist', 3): 0,\n",
       " ('therefor', 3): 0,\n",
       " ('unifi', 3): 0,\n",
       " ('qualiti', 3): 0,\n",
       " ('rather', 3): 0,\n",
       " ('challeng', 3): 0,\n",
       " ('firstli', 3): 0,\n",
       " ('hard', 3): 0,\n",
       " ('simultan', 3): 0,\n",
       " ('secondli', 3): 0,\n",
       " ('non-trivi', 3): 0,\n",
       " ('express', 3): 0,\n",
       " ('effect', 3): 0,\n",
       " ('henc', 3): 0,\n",
       " ('design', 3): 0,\n",
       " ('framework', 3): 0,\n",
       " ('tgsrec', 3): 0,\n",
       " ('upon', 3): 0,\n",
       " ('continuous-tim', 3): 0,\n",
       " ('bipartit', 3): 0,\n",
       " ('novel', 3): 0,\n",
       " ('transform', 3): 0,\n",
       " ('tct', 3): 0,\n",
       " ('layer', 3): 0,\n",
       " ('advanc', 3): 0,\n",
       " ('self-attent', 3): 0,\n",
       " ('mechan', 3): 0,\n",
       " ('captur', 3): 0,\n",
       " ('well', 3): 0,\n",
       " ('consid', 3): 0,\n",
       " ('dynam', 3): 0,\n",
       " ('insid', 3): 0,\n",
       " ('propag', 3): 0,\n",
       " ('empir', 3): 0,\n",
       " ('five', 3): 0,\n",
       " ('modelnam', 3): 0,\n",
       " ('significantli', 3): 0,\n",
       " ('outperform', 3): 0,\n",
       " ('baselin', 3): 0,\n",
       " ('22.5%', 3): 0,\n",
       " ('22.1%', 3): 0,\n",
       " ('absolut', 3): 0,\n",
       " ('recal', 3): 0,\n",
       " ('10', 3): 0,\n",
       " ('mrr', 3): 0,\n",
       " ('contain', 3): 0,\n",
       " ('well-structur', 3): 0,\n",
       " ('extern', 3): 0,\n",
       " ('shown', 3): 0,\n",
       " ('high-qual', 3): 0,\n",
       " ('enhanc', 3): 0,\n",
       " ('larg', 3): 0,\n",
       " ('focus', 3): 0,\n",
       " ('architectur', 3): 0,\n",
       " ('investig', 3): 0,\n",
       " ('structur', 3): 0,\n",
       " ('mainli', 3): 0,\n",
       " ('reli', 3): 0,\n",
       " ('neg', 3): 0,\n",
       " ('sampl', 3): 0,\n",
       " ('ns', 3): 0,\n",
       " ('optim', 3): 0,\n",
       " ('task', 3): 0,\n",
       " ('sinc', 3): 0,\n",
       " ('robust', 3): 0,\n",
       " ('small', 3): 0,\n",
       " ('fraction', 3): 0,\n",
       " ('instanc', 3): 0,\n",
       " ('may', 3): 0,\n",
       " ('lose', 3): 0,\n",
       " ('lot', 3): 0,\n",
       " ('reason', 3): 0,\n",
       " ('argu', 3): 0,\n",
       " ('insuffici', 3): 0,\n",
       " ('among', 3): 0,\n",
       " ('entiti', 3): 0,\n",
       " ('paper', 3): 0,\n",
       " ('jointli', 3): 0,\n",
       " ('non-sampl', 3): 0,\n",
       " ('jnskr', 3): 0,\n",
       " ('effici', 3): 0,\n",
       " ('subgraph', 3): 0,\n",
       " ('character', 3): 0,\n",
       " ('memor', 3): 0,\n",
       " ('strategi', 3): 0,\n",
       " ('joint', 3): 0,\n",
       " ('also', 3): 0,\n",
       " ('paramet', 3): 0,\n",
       " ('whole', 3): 0,\n",
       " ('train', 3): 0,\n",
       " ('includ', 3): 0,\n",
       " ('non-observ', 3): 0,\n",
       " ('low', 3): 0,\n",
       " ('time', 3): 0,\n",
       " ('complex', 3): 0,\n",
       " ('two', 3): 0,\n",
       " ('public', 3): 0,\n",
       " ('ripplenet', 3): 0,\n",
       " ('remark', 3): 0,\n",
       " ('advantag', 3): 0,\n",
       " ('20', 3): 0,\n",
       " ('faster', 3): 0,\n",
       " ('make', 3): 0,\n",
       " ('real-world', 3): 0,\n",
       " ('large-scal', 3): 0,\n",
       " ('knowledg', 4): 3,\n",
       " ('graph', 4): 3,\n",
       " ('kg', 4): 4,\n",
       " ('contain', 4): 1,\n",
       " ('well-structur', 4): 1,\n",
       " ('extern', 4): 1,\n",
       " ('inform', 4): 4,\n",
       " ('shown', 4): 1,\n",
       " ('effect', 4): 1,\n",
       " ('high-qual', 4): 1,\n",
       " ('recommend', 4): 4,\n",
       " ('howev', 4): 1,\n",
       " ('exist', 4): 1,\n",
       " ('enhanc', 4): 2,\n",
       " ('method', 4): 4,\n",
       " ('larg', 4): 1,\n",
       " ('focus', 4): 1,\n",
       " ('explor', 4): 1,\n",
       " ('advanc', 4): 1,\n",
       " ('neural', 4): 2,\n",
       " ('network', 4): 2,\n",
       " ('architectur', 4): 1,\n",
       " ('better', 4): 2,\n",
       " ('investig', 4): 1,\n",
       " ('structur', 4): 1,\n",
       " ('model', 4): 5,\n",
       " ('learn', 4): 5,\n",
       " ('mainli', 4): 1,\n",
       " ('reli', 4): 1,\n",
       " ('neg', 4): 2,\n",
       " ('sampl', 4): 2,\n",
       " ('ns', 4): 3,\n",
       " ('optim', 4): 2,\n",
       " ('embed', 4): 2,\n",
       " ('task', 4): 2,\n",
       " ('sinc', 4): 1,\n",
       " ('robust', 4): 1,\n",
       " ('e.g.', 4): 1,\n",
       " ('small', 4): 1,\n",
       " ('fraction', 4): 1,\n",
       " ('instanc', 4): 1,\n",
       " ('may', 4): 1,\n",
       " ('lose', 4): 1,\n",
       " ('lot', 4): 1,\n",
       " ('use', 4): 1,\n",
       " ('reason', 4): 1,\n",
       " ('argu', 4): 1,\n",
       " ('insuffici', 4): 1,\n",
       " ('captur', 4): 1,\n",
       " ('collabor', 4): 1,\n",
       " ('among', 4): 2,\n",
       " ('user', 4): 3,\n",
       " ('item', 4): 3,\n",
       " ('entiti', 4): 2,\n",
       " ('paper', 4): 1,\n",
       " ('propos', 4): 2,\n",
       " ('novel', 4): 2,\n",
       " ('jointli', 4): 1,\n",
       " ('non-sampl', 4): 1,\n",
       " ('jnskr', 4): 4,\n",
       " ('specif', 4): 1,\n",
       " ('first', 4): 1,\n",
       " ('design', 4): 2,\n",
       " ('new', 4): 1,\n",
       " ('effici', 4): 3,\n",
       " ('algorithm', 4): 1,\n",
       " ('subgraph', 4): 1,\n",
       " ('encod', 4): 1,\n",
       " ('attent', 4): 1,\n",
       " ('character', 4): 1,\n",
       " ('prefer', 4): 1,\n",
       " ('memor', 4): 1,\n",
       " ('strategi', 4): 1,\n",
       " ('joint', 4): 1,\n",
       " ('framework', 4): 1,\n",
       " ('fine-grain', 4): 1,\n",
       " ('connect', 4): 1,\n",
       " ('also', 4): 2,\n",
       " ('paramet', 4): 1,\n",
       " ('whole', 4): 1,\n",
       " ('train', 4): 2,\n",
       " ('data', 4): 2,\n",
       " ('includ', 4): 1,\n",
       " ('non-observ', 4): 1,\n",
       " ('rather', 4): 1,\n",
       " ('low', 4): 1,\n",
       " ('time', 4): 2,\n",
       " ('complex', 4): 1,\n",
       " ('experiment', 4): 1,\n",
       " ('result', 4): 1,\n",
       " ('two', 4): 1,\n",
       " ('public', 4): 1,\n",
       " ('benchmark', 4): 1,\n",
       " ('show', 4): 2,\n",
       " ('significantli', 4): 1,\n",
       " ('outperform', 4): 1,\n",
       " ('state-of-the-art', 4): 1,\n",
       " ('like', 4): 1,\n",
       " ('ripplenet', 4): 1,\n",
       " ('kgat', 4): 2,\n",
       " ('remark', 4): 1,\n",
       " ('signific', 4): 1,\n",
       " ('advantag', 4): 1,\n",
       " ('20', 4): 1,\n",
       " ('faster', 4): 1,\n",
       " ('make', 4): 1,\n",
       " ('applic', 4): 1,\n",
       " ('real-world', 4): 1,\n",
       " ('large-scal', 4): 1,\n",
       " ('system', 4): 1,\n",
       " ('play', 4): 0,\n",
       " ('increasingli', 4): 0,\n",
       " ('import', 4): 0,\n",
       " ('role', 4): 0,\n",
       " ('recent', 4): 0,\n",
       " ('technic', 4): 0,\n",
       " ('trend', 4): 0,\n",
       " ('develop', 4): 0,\n",
       " ('end-to-end', 4): 0,\n",
       " ('found', 4): 0,\n",
       " ('gnn', 4): 0,\n",
       " ('gnn-base', 4): 0,\n",
       " ('coarse-grain', 4): 0,\n",
       " ('relat', 4): 0,\n",
       " ('fail', 4): 0,\n",
       " ('1', 4): 0,\n",
       " ('identifi', 4): 0,\n",
       " ('user-item', 4): 0,\n",
       " ('level', 4): 0,\n",
       " ('intent', 4): 0,\n",
       " ('2', 4): 0,\n",
       " ('exploit', 4): 0,\n",
       " ('depend', 4): 0,\n",
       " ('preserv', 4): 0,\n",
       " ('semant', 4): 0,\n",
       " ('long-rang', 4): 0,\n",
       " ('studi', 4): 0,\n",
       " ('behind', 4): 0,\n",
       " ('interact', 4): 0,\n",
       " ('auxiliari', 4): 0,\n",
       " ('graph-bas', 4): 0,\n",
       " ('kgin', 4): 0,\n",
       " ('combin', 4): 0,\n",
       " ('encourag', 4): 0,\n",
       " ('independ', 4): 0,\n",
       " ('differ', 4): 0,\n",
       " ('capabl', 4): 0,\n",
       " ('interpret', 4): 0,\n",
       " ('furthermor', 4): 0,\n",
       " ('devis', 4): 0,\n",
       " ('aggreg', 4): 0,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TermesFrequence={}\n",
    "TousTermes=TermesNormalisation1+TermesNormalisation2+TermesNormalisation3+TermesNormalisation4\n",
    "for terme in TermesNormalisation1:\n",
    "    if ((terme,1) in TermesFrequence.keys()):\n",
    "        TermesFrequence[(terme,1)] += 1\n",
    "    else:\n",
    "        TermesFrequence[(terme,1)] = 1\n",
    "for terme in TousTermes:\n",
    "    if terme not in TermesNormalisation1:\n",
    "        TermesFrequence[(terme,1)] = 0\n",
    "\n",
    "for terme in TermesNormalisation2:\n",
    "    if ((terme,2) in TermesFrequence.keys()):\n",
    "        TermesFrequence[(terme,2)] += 1\n",
    "    else:\n",
    "        TermesFrequence[(terme,2)] = 1\n",
    "for terme in TousTermes:\n",
    "    if terme not in TermesNormalisation2:\n",
    "        TermesFrequence[(terme,2)] = 0\n",
    "\n",
    "for terme in TermesNormalisation3:\n",
    "    if ((terme,3) in TermesFrequence.keys()):\n",
    "        TermesFrequence[(terme,3)] += 1\n",
    "    else:\n",
    "        TermesFrequence[(terme,3)] = 1\n",
    "for terme in TousTermes:\n",
    "    if terme not in TermesNormalisation3:\n",
    "        TermesFrequence[(terme,3)] = 0\n",
    "\n",
    "for terme in TermesNormalisation4:\n",
    "    if ((terme,4) in TermesFrequence.keys()):\n",
    "        TermesFrequence[(terme,4)] += 1\n",
    "    else:\n",
    "        TermesFrequence[(terme,4)] = 1\n",
    "for terme in TousTermes:\n",
    "    if terme not in TermesNormalisation4:\n",
    "        TermesFrequence[(terme,4)] = 0\n",
    "\n",
    "TermesFrequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': 1,\n",
       " 'model': 2,\n",
       " 'evolut': 1,\n",
       " 'user': 2,\n",
       " 'prefer': 1,\n",
       " 'learn': 2,\n",
       " 'user-item': 2,\n",
       " 'embed': 1,\n",
       " 'base': 1,\n",
       " 'time-ord': 1,\n",
       " 'item': 3,\n",
       " 'purchas': 1,\n",
       " 'sequenc': 1,\n",
       " 'defin': 2,\n",
       " 'sequenti': 8,\n",
       " 'recommend': 3,\n",
       " 'sr': 1,\n",
       " 'problem': 1,\n",
       " 'exist': 1,\n",
       " 'method': 1,\n",
       " 'leverag': 1,\n",
       " 'pattern': 6,\n",
       " 'transit': 1,\n",
       " 'howev': 1,\n",
       " 'ignor': 1,\n",
       " 'crucial': 1,\n",
       " 'tempor': 8,\n",
       " 'collabor': 8,\n",
       " 'signal': 6,\n",
       " 'latent': 1,\n",
       " 'evolv': 1,\n",
       " 'interact': 1,\n",
       " 'coexist': 1,\n",
       " 'therefor': 1,\n",
       " 'propos': 2,\n",
       " 'unifi': 2,\n",
       " 'improv': 2,\n",
       " 'qualiti': 1,\n",
       " 'rather': 1,\n",
       " 'challeng': 1,\n",
       " 'firstli': 1,\n",
       " 'hard': 1,\n",
       " 'simultan': 2,\n",
       " 'encod': 1,\n",
       " 'secondli': 1,\n",
       " 'non-trivi': 1,\n",
       " 'express': 1,\n",
       " 'effect': 1,\n",
       " 'henc': 1,\n",
       " 'design': 1,\n",
       " 'new': 1,\n",
       " 'framework': 1,\n",
       " 'graph': 3,\n",
       " 'tgsrec': 2,\n",
       " 'upon': 1,\n",
       " 'continuous-tim': 1,\n",
       " 'bipartit': 1,\n",
       " 'novel': 2,\n",
       " 'transform': 1,\n",
       " 'tct': 3,\n",
       " 'layer': 3,\n",
       " 'advanc': 1,\n",
       " 'self-attent': 1,\n",
       " 'mechan': 1,\n",
       " 'adopt': 1,\n",
       " 'attent': 1,\n",
       " 'captur': 1,\n",
       " 'well': 1,\n",
       " 'consid': 1,\n",
       " 'dynam': 1,\n",
       " 'insid': 1,\n",
       " 'propag': 1,\n",
       " 'inform': 1,\n",
       " 'empir': 1,\n",
       " 'result': 1,\n",
       " 'five': 1,\n",
       " 'dataset': 1,\n",
       " 'show': 1,\n",
       " 'modelnam': 1,\n",
       " 'significantli': 1,\n",
       " 'outperform': 1,\n",
       " 'baselin': 1,\n",
       " 'averag': 1,\n",
       " '22.5%': 1,\n",
       " '22.1%': 1,\n",
       " 'absolut': 1,\n",
       " 'recal': 1,\n",
       " '10': 1,\n",
       " 'mrr': 1,\n",
       " 'respect': 1,\n",
       " 'knowledg': 0,\n",
       " 'kg': 0,\n",
       " 'play': 0,\n",
       " 'increasingli': 0,\n",
       " 'import': 0,\n",
       " 'role': 0,\n",
       " 'system': 0,\n",
       " 'recent': 0,\n",
       " 'technic': 0,\n",
       " 'trend': 0,\n",
       " 'develop': 0,\n",
       " 'end-to-end': 0,\n",
       " 'found': 0,\n",
       " 'neural': 0,\n",
       " 'network': 0,\n",
       " 'gnn': 0,\n",
       " 'gnn-base': 0,\n",
       " 'coarse-grain': 0,\n",
       " 'relat': 0,\n",
       " 'fail': 0,\n",
       " '1': 0,\n",
       " 'identifi': 0,\n",
       " 'fine-grain': 0,\n",
       " 'level': 0,\n",
       " 'intent': 0,\n",
       " '2': 0,\n",
       " 'exploit': 0,\n",
       " 'depend': 0,\n",
       " 'preserv': 0,\n",
       " 'semant': 0,\n",
       " 'long-rang': 0,\n",
       " 'connect': 0,\n",
       " 'studi': 0,\n",
       " 'explor': 0,\n",
       " 'behind': 0,\n",
       " 'use': 0,\n",
       " 'auxiliari': 0,\n",
       " 'graph-bas': 0,\n",
       " 'kgin': 0,\n",
       " 'combin': 0,\n",
       " 'encourag': 0,\n",
       " 'independ': 0,\n",
       " 'differ': 0,\n",
       " 'better': 0,\n",
       " 'capabl': 0,\n",
       " 'interpret': 0,\n",
       " 'furthermor': 0,\n",
       " 'devis': 0,\n",
       " 'aggreg': 0,\n",
       " 'scheme': 0,\n",
       " 'recurs': 0,\n",
       " 'integr': 0,\n",
       " 'i.e.': 0,\n",
       " 'path': 0,\n",
       " 'allow': 0,\n",
       " 'us': 0,\n",
       " 'distil': 0,\n",
       " 'represent': 0,\n",
       " 'experiment': 0,\n",
       " 'three': 0,\n",
       " 'benchmark': 0,\n",
       " 'achiev': 0,\n",
       " 'signific': 0,\n",
       " 'state-of-the-art': 0,\n",
       " 'like': 0,\n",
       " 'kgat': 0,\n",
       " '41': 0,\n",
       " 'kgnn-l': 0,\n",
       " '38': 0,\n",
       " 'ckan': 0,\n",
       " '47': 0,\n",
       " 'analys': 0,\n",
       " 'offer': 0,\n",
       " 'explan': 0,\n",
       " 'predict': 0,\n",
       " 'influenti': 0,\n",
       " 'motiv': 0,\n",
       " 'vast': 0,\n",
       " 'applic': 0,\n",
       " 'increas': 0,\n",
       " 'demand': 0,\n",
       " 'educ': 0,\n",
       " 'domain': 0,\n",
       " 'call': 0,\n",
       " 'knowedu': 0,\n",
       " 'automat': 0,\n",
       " 'construct': 0,\n",
       " 'heterogen': 0,\n",
       " 'data': 0,\n",
       " 'e.g.': 0,\n",
       " 'pedagog': 0,\n",
       " 'assess': 0,\n",
       " 'first': 0,\n",
       " 'extract': 0,\n",
       " 'concept': 0,\n",
       " 'subject': 0,\n",
       " 'cours': 0,\n",
       " 'specif': 0,\n",
       " 'label': 0,\n",
       " 'algorithm': 0,\n",
       " 'instruct': 0,\n",
       " 'employ': 0,\n",
       " 'probabilist': 0,\n",
       " 'associ': 0,\n",
       " 'rule': 0,\n",
       " 'mine': 0,\n",
       " 'detail': 0,\n",
       " 'mention': 0,\n",
       " 'effort': 0,\n",
       " 'exemplari': 0,\n",
       " 'case': 0,\n",
       " 'demonstr': 0,\n",
       " 'mathemat': 0,\n",
       " 'prerequisit': 0,\n",
       " 'deriv': 0,\n",
       " 'curriculum': 0,\n",
       " 'standard': 0,\n",
       " 'concept-bas': 0,\n",
       " 'perform': 0,\n",
       " 'student': 0,\n",
       " 'evalu': 0,\n",
       " 'f1': 0,\n",
       " 'score': 0,\n",
       " 'exce': 0,\n",
       " '0.': 0,\n",
       " '70': 0,\n",
       " 'identif': 0,\n",
       " 'area': 0,\n",
       " 'curv': 0,\n",
       " 'mean': 0,\n",
       " 'precis': 0,\n",
       " '95': 0,\n",
       " '87': 0,\n",
       " 'contain': 0,\n",
       " 'well-structur': 0,\n",
       " 'extern': 0,\n",
       " 'shown': 0,\n",
       " 'high-qual': 0,\n",
       " 'enhanc': 0,\n",
       " 'larg': 0,\n",
       " 'focus': 0,\n",
       " 'architectur': 0,\n",
       " 'investig': 0,\n",
       " 'structur': 0,\n",
       " 'mainli': 0,\n",
       " 'reli': 0,\n",
       " 'neg': 0,\n",
       " 'sampl': 0,\n",
       " 'ns': 0,\n",
       " 'optim': 0,\n",
       " 'task': 0,\n",
       " 'sinc': 0,\n",
       " 'robust': 0,\n",
       " 'small': 0,\n",
       " 'fraction': 0,\n",
       " 'instanc': 0,\n",
       " 'may': 0,\n",
       " 'lose': 0,\n",
       " 'lot': 0,\n",
       " 'reason': 0,\n",
       " 'argu': 0,\n",
       " 'insuffici': 0,\n",
       " 'among': 0,\n",
       " 'entiti': 0,\n",
       " 'paper': 0,\n",
       " 'jointli': 0,\n",
       " 'non-sampl': 0,\n",
       " 'jnskr': 0,\n",
       " 'effici': 0,\n",
       " 'subgraph': 0,\n",
       " 'character': 0,\n",
       " 'memor': 0,\n",
       " 'strategi': 0,\n",
       " 'joint': 0,\n",
       " 'also': 0,\n",
       " 'paramet': 0,\n",
       " 'whole': 0,\n",
       " 'train': 0,\n",
       " 'includ': 0,\n",
       " 'non-observ': 0,\n",
       " 'low': 0,\n",
       " 'time': 0,\n",
       " 'complex': 0,\n",
       " 'two': 0,\n",
       " 'public': 0,\n",
       " 'ripplenet': 0,\n",
       " 'remark': 0,\n",
       " 'advantag': 0,\n",
       " '20': 0,\n",
       " 'faster': 0,\n",
       " 'make': 0,\n",
       " 'real-world': 0,\n",
       " 'large-scal': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freq1(dico, docu):\n",
    "        keys = dico.keys()\n",
    "        docu_keys = []\n",
    "        for each in keys:\n",
    "                if docu == each[1]:\n",
    "                        docu_keys.append(each)\n",
    "        response = {}\n",
    "        for key in docu_keys:\n",
    "                response[key[0]] = dico[key]\n",
    "        return response\n",
    "\n",
    "freq1(TermesFrequence, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 1, 4: 1}\n",
      "{1: 0, 2: 1, 3: 0, 4: 0}\n",
      "{1: 3, 2: 0, 3: 3, 4: 3}\n"
     ]
    }
   ],
   "source": [
    "def freq2(dico, terme):\n",
    "        terme = terme.strip()\n",
    "        terme = Porter.stem(terme.lower())\n",
    "        keys = dico.keys()\n",
    "        docu_keys = []\n",
    "        for each in keys:\n",
    "                if terme == each[0]:\n",
    "                        docu_keys.append(each)\n",
    "        response = {}\n",
    "        for key in docu_keys:\n",
    "                response[key[1]] = dico[key]\n",
    "        return response\n",
    "\n",
    "print(freq2(TermesFrequence, 'E.G.'))\n",
    "print(freq2(TermesFrequence, '22.5%'))\n",
    "print(freq2(TermesFrequence, 'knowledge'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def poid(dico, terme, docu):\n",
    "        freqs = freq2(dico,terme)\n",
    "        try:\n",
    "                term_freq_in_docu = freqs[docu]\n",
    "                values = []\n",
    "                for each in dico.keys():\n",
    "                        if each[1] == docu:\n",
    "                                values.append(dico[each])\n",
    "                max_val = max(values)\n",
    "                c = 0\n",
    "                for each in freqs.keys():\n",
    "                        if freqs[each] !=0:\n",
    "                                c+=1\n",
    "                log_part = math.log10((len(freqs)/c)+1)\n",
    "                other_part = term_freq_in_docu/max_val\n",
    "                return other_part*log_part\n",
    "        except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def poid_normalise(dico, terme, docu):\n",
    "        try:\n",
    "                k = 2\n",
    "                b = 0.5\n",
    "                distinct_docus = {}\n",
    "                for each in dico.keys():\n",
    "                        if each[1] in distinct_docus.keys():\n",
    "                                distinct_docus[each[1]] += dico[each]\n",
    "                        else: distinct_docus[each[1]] = dico[each]\n",
    "                \n",
    "                freqs = freq2(dico,terme)\n",
    "                term_freq_in_docu = freqs[docu]\n",
    "                c = 0\n",
    "                for each in freqs.keys():\n",
    "                        if freqs[each] !=0:\n",
    "                                c+=1\n",
    "                values = []\n",
    "                for each in distinct_docus.keys():\n",
    "                        values.append(distinct_docus[each])\n",
    "                part_idk = k*((1-b)+b*(distinct_docus[docu]/np.mean(values)))\n",
    "                log_part = math.log10((len(freqs)-c+0.5)/(c+0.5))\n",
    "                return ((term_freq_in_docu/(part_idk+term_freq_in_docu))*log_part)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043004285094854454"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poid(TermesFrequence, 'result', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31963624399312346"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poid_normalise(TermesFrequence, 'result', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terme entrée docu cle frequence poid1 poid2 values\n",
    "def get_weights(dico, terme):\n",
    "        frequencies = freq2(dico, terme)\n",
    "        new_dict = {}\n",
    "        for each in frequencies.keys():\n",
    "                poid_simple = poid(dico, terme, each)\n",
    "                poid_normal = poid_normalise(dico, terme, each)\n",
    "                new_dict[each] = (frequencies[each], poid_simple, poid_normal)\n",
    "        return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (1, 0.043004285094854454, -0.31963624399312346),\n",
       " 2: (1, 0.03762874945799765, -0.31425774950285457),\n",
       " 3: (1, 0.050171665943996864, -0.3440295362978618),\n",
       " 4: (1, 0.06020599913279624, -0.29779322048562074)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weights(TermesFrequence, 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('knowledg', 1): (3, 0.15770433655482613, -0.22143258968679108),\n",
       " ('graph', 1): (2, 0.08600857018970891, -0.47886895162339743),\n",
       " ('kg', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('play', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('increasingli', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('import', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('role', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('recommend', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('system', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('recent', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('technic', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('trend', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('develop', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('end-to-end', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('model', 1): (6, 0.31540867310965226, -0.27648712752482324),\n",
       " ('found', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('neural', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('network', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('gnn', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('howev', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('exist', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('gnn-base', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('coarse-grain', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('relat', 1): (7, 0.47712125471966244, 0.0),\n",
       " ('fail', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('1', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('identifi', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('user-item', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('fine-grain', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('level', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('intent', 1): (7, 0.6989700043360189, 0.2866691609240586),\n",
       " ('2', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('exploit', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('depend', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('preserv', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('semant', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('long-rang', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('connect', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('studi', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('explor', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('behind', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('interact', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('use', 1): (2, 0.13632035849133212, 0.0),\n",
       " ('auxiliari', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('item', 1): (2, 0.10513622436988408, -0.18466234280351443),\n",
       " ('propos', 1): (1, None, None),\n",
       " ('new', 1): (2, 0.10513622436988408, -0.18466234280351443),\n",
       " ('graph-bas', 1): (1, None, None),\n",
       " ('kgin', 1): (3, 0.2995585732868652, 0.22143258968679108),\n",
       " ('attent', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('combin', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('encourag', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('independ', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('differ', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('better', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('capabl', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('interpret', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('furthermor', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('devis', 1): (1, None, None),\n",
       " ('inform', 1): (2, 0.10513622436988408, -0.18466234280351443),\n",
       " ('aggreg', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('scheme', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('recurs', 1): (1, None, None),\n",
       " ('integr', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('sequenc', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('i.e.', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('path', 1): (2, 0.1997057155245768, 0.18466234280351443),\n",
       " ('allow', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('us', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('distil', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('user', 1): (2, 0.10513622436988408, -0.18466234280351443),\n",
       " ('encod', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('represent', 1): (1, None, None),\n",
       " ('experiment', 1): (1, None, None),\n",
       " ('result', 1): (1, 0.043004285094854454, -0.31963624399312346),\n",
       " ('three', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('benchmark', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('dataset', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('show', 1): (2, 0.08600857018970891, -0.47886895162339743),\n",
       " ('achiev', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('signific', 1): (1, None, None),\n",
       " ('improv', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('state-of-the-art', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('method', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('like', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('kgat', 1): (1, 0.06816017924566606, 0.0),\n",
       " ('41', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('kgnn-l', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('38', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('ckan', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('47', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('analys', 1): (1, None, None),\n",
       " ('offer', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('explan', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('predict', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('influenti', 1): (1, 0.0998528577622884, 0.12325872759256586),\n",
       " ('order', 1): (0, 0.0, 0.0),\n",
       " ('evolut', 1): (0, 0.0, 0.0),\n",
       " ('prefer', 1): (0, 0.0, 0.0),\n",
       " ('learn', 1): (0, 0.0, -0.0),\n",
       " ('embed', 1): (0, None, None),\n",
       " ('base', 1): (0, 0.0, 0.0),\n",
       " ('time-ord', 1): (0, 0.0, 0.0),\n",
       " ('purchas', 1): (0, None, None),\n",
       " ('defin', 1): (0, 0.0, 0.0),\n",
       " ('sequenti', 1): (0, 0.0, 0.0),\n",
       " ('sr', 1): (0, 0.0, 0.0),\n",
       " ('problem', 1): (0, 0.0, 0.0),\n",
       " ('leverag', 1): (0, 0.0, 0.0),\n",
       " ('pattern', 1): (0, 0.0, 0.0),\n",
       " ('transit', 1): (0, 0.0, 0.0),\n",
       " ('ignor', 1): (0, 0.0, 0.0),\n",
       " ('crucial', 1): (0, 0.0, 0.0),\n",
       " ('tempor', 1): (0, 0.0, 0.0),\n",
       " ('collabor', 1): (0, 0.0, 0.0),\n",
       " ('signal', 1): (0, 0.0, 0.0),\n",
       " ('latent', 1): (0, 0.0, 0.0),\n",
       " ('evolv', 1): (0, 0.0, 0.0),\n",
       " ('coexist', 1): (0, 0.0, 0.0),\n",
       " ('therefor', 1): (0, 0.0, 0.0),\n",
       " ('unifi', 1): (0, 0.0, 0.0),\n",
       " ('qualiti', 1): (0, 0.0, 0.0),\n",
       " ('rather', 1): (0, 0.0, 0.0),\n",
       " ('challeng', 1): (0, 0.0, 0.0),\n",
       " ('firstli', 1): (0, 0.0, 0.0),\n",
       " ('hard', 1): (0, 0.0, 0.0),\n",
       " ('simultan', 1): (0, 0.0, 0.0),\n",
       " ('secondli', 1): (0, 0.0, 0.0),\n",
       " ('non-trivi', 1): (0, 0.0, 0.0),\n",
       " ('express', 1): (0, 0.0, 0.0),\n",
       " ('effect', 1): (0, 0.0, 0.0),\n",
       " ('henc', 1): (0, 0.0, 0.0),\n",
       " ('design', 1): (0, 0.0, 0.0),\n",
       " ('framework', 1): (0, 0.0, 0.0),\n",
       " ('tgsrec', 1): (0, 0.0, 0.0),\n",
       " ('upon', 1): (0, 0.0, 0.0),\n",
       " ('continuous-tim', 1): (0, 0.0, 0.0),\n",
       " ('bipartit', 1): (0, 0.0, 0.0),\n",
       " ('novel', 1): (0, 0.0, 0.0),\n",
       " ('transform', 1): (0, 0.0, 0.0),\n",
       " ('tct', 1): (0, 0.0, 0.0),\n",
       " ('layer', 1): (0, 0.0, 0.0),\n",
       " ('advanc', 1): (0, 0.0, 0.0),\n",
       " ('self-attent', 1): (0, None, None),\n",
       " ('mechan', 1): (0, 0.0, 0.0),\n",
       " ('adopt', 1): (0, 0.0, 0.0),\n",
       " ('captur', 1): (0, 0.0, 0.0),\n",
       " ('well', 1): (0, 0.0, 0.0),\n",
       " ('consid', 1): (0, 0.0, 0.0),\n",
       " ('dynam', 1): (0, 0.0, 0.0),\n",
       " ('insid', 1): (0, 0.0, 0.0),\n",
       " ('propag', 1): (0, 0.0, 0.0),\n",
       " ('empir', 1): (0, 0.0, 0.0),\n",
       " ('five', 1): (0, 0.0, 0.0),\n",
       " ('modelnam', 1): (0, 0.0, 0.0),\n",
       " ('significantli', 1): (0, 0.0, 0.0),\n",
       " ('outperform', 1): (0, 0.0, 0.0),\n",
       " ('baselin', 1): (0, 0.0, 0.0),\n",
       " ('averag', 1): (0, 0.0, 0.0),\n",
       " ('22.5%', 1): (0, 0.0, 0.0),\n",
       " ('22.1%', 1): (0, 0.0, 0.0),\n",
       " ('absolut', 1): (0, 0.0, 0.0),\n",
       " ('recal', 1): (0, 0.0, 0.0),\n",
       " ('10', 1): (0, 0.0, 0.0),\n",
       " ('mrr', 1): (0, 0.0, 0.0),\n",
       " ('respect', 1): (0, 0.0, 0.0),\n",
       " ('motiv', 1): (0, 0.0, 0.0),\n",
       " ('vast', 1): (0, 0.0, 0.0),\n",
       " ('applic', 1): (0, 0.0, 0.0),\n",
       " ('increas', 1): (0, None, None),\n",
       " ('demand', 1): (0, 0.0, 0.0),\n",
       " ('educ', 1): (0, 0.0, 0.0),\n",
       " ('domain', 1): (0, 0.0, 0.0),\n",
       " ('call', 1): (0, 0.0, 0.0),\n",
       " ('knowedu', 1): (0, 0.0, 0.0),\n",
       " ('automat', 1): (0, 0.0, 0.0),\n",
       " ('construct', 1): (0, 0.0, 0.0),\n",
       " ('heterogen', 1): (0, 0.0, 0.0),\n",
       " ('data', 1): (0, 0.0, 0.0),\n",
       " ('e.g.', 1): (0, 0.0, 0.0),\n",
       " ('pedagog', 1): (0, 0.0, 0.0),\n",
       " ('assess', 1): (0, 0.0, 0.0),\n",
       " ('first', 1): (0, 0.0, 0.0),\n",
       " ('extract', 1): (0, 0.0, 0.0),\n",
       " ('concept', 1): (0, 0.0, 0.0),\n",
       " ('subject', 1): (0, 0.0, 0.0),\n",
       " ('cours', 1): (0, None, None),\n",
       " ('specif', 1): (0, 0.0, 0.0),\n",
       " ('label', 1): (0, 0.0, 0.0),\n",
       " ('algorithm', 1): (0, 0.0, 0.0),\n",
       " ('instruct', 1): (0, 0.0, 0.0),\n",
       " ('employ', 1): (0, 0.0, 0.0),\n",
       " ('probabilist', 1): (0, 0.0, 0.0),\n",
       " ('associ', 1): (0, 0.0, 0.0),\n",
       " ('rule', 1): (0, 0.0, 0.0),\n",
       " ('mine', 1): (0, 0.0, 0.0),\n",
       " ('detail', 1): (0, 0.0, 0.0),\n",
       " ('mention', 1): (0, 0.0, 0.0),\n",
       " ('effort', 1): (0, 0.0, 0.0),\n",
       " ('exemplari', 1): (0, 0.0, 0.0),\n",
       " ('case', 1): (0, 0.0, 0.0),\n",
       " ('demonstr', 1): (0, 0.0, 0.0),\n",
       " ('mathemat', 1): (0, 0.0, 0.0),\n",
       " ('prerequisit', 1): (0, 0.0, 0.0),\n",
       " ('deriv', 1): (0, 0.0, 0.0),\n",
       " ('curriculum', 1): (0, 0.0, 0.0),\n",
       " ('standard', 1): (0, 0.0, 0.0),\n",
       " ('concept-bas', 1): (0, None, None),\n",
       " ('perform', 1): (0, 0.0, 0.0),\n",
       " ('student', 1): (0, 0.0, 0.0),\n",
       " ('evalu', 1): (0, 0.0, 0.0),\n",
       " ('f1', 1): (0, 0.0, 0.0),\n",
       " ('score', 1): (0, 0.0, 0.0),\n",
       " ('exce', 1): (0, None, None),\n",
       " ('0.', 1): (0, 0.0, 0.0),\n",
       " ('70', 1): (0, 0.0, 0.0),\n",
       " ('identif', 1): (0, 0.0, 0.0),\n",
       " ('area', 1): (0, 0.0, 0.0),\n",
       " ('curv', 1): (0, 0.0, 0.0),\n",
       " ('mean', 1): (0, 0.0, 0.0),\n",
       " ('precis', 1): (0, None, None),\n",
       " ('95', 1): (0, 0.0, 0.0),\n",
       " ('87', 1): (0, 0.0, 0.0),\n",
       " ('contain', 1): (0, 0.0, 0.0),\n",
       " ('well-structur', 1): (0, 0.0, 0.0),\n",
       " ('extern', 1): (0, 0.0, 0.0),\n",
       " ('shown', 1): (0, 0.0, 0.0),\n",
       " ('high-qual', 1): (0, 0.0, 0.0),\n",
       " ('enhanc', 1): (0, 0.0, 0.0),\n",
       " ('larg', 1): (0, 0.0, 0.0),\n",
       " ('focus', 1): (0, None, None),\n",
       " ('architectur', 1): (0, 0.0, 0.0),\n",
       " ('investig', 1): (0, 0.0, 0.0),\n",
       " ('structur', 1): (0, 0.0, 0.0),\n",
       " ('mainli', 1): (0, 0.0, 0.0),\n",
       " ('reli', 1): (0, 0.0, 0.0),\n",
       " ('neg', 1): (0, 0.0, 0.0),\n",
       " ('sampl', 1): (0, 0.0, 0.0),\n",
       " ('ns', 1): (0, 0.0, 0.0),\n",
       " ('optim', 1): (0, 0.0, 0.0),\n",
       " ('task', 1): (0, 0.0, 0.0),\n",
       " ('sinc', 1): (0, 0.0, 0.0),\n",
       " ('robust', 1): (0, 0.0, 0.0),\n",
       " ('small', 1): (0, 0.0, 0.0),\n",
       " ('fraction', 1): (0, 0.0, 0.0),\n",
       " ('instanc', 1): (0, 0.0, 0.0),\n",
       " ('may', 1): (0, 0.0, 0.0),\n",
       " ('lose', 1): (0, 0.0, 0.0),\n",
       " ('lot', 1): (0, 0.0, 0.0),\n",
       " ('reason', 1): (0, 0.0, 0.0),\n",
       " ('argu', 1): (0, 0.0, 0.0),\n",
       " ('insuffici', 1): (0, 0.0, 0.0),\n",
       " ('among', 1): (0, 0.0, 0.0),\n",
       " ('entiti', 1): (0, 0.0, 0.0),\n",
       " ('paper', 1): (0, 0.0, 0.0),\n",
       " ('jointli', 1): (0, 0.0, 0.0),\n",
       " ('non-sampl', 1): (0, 0.0, 0.0),\n",
       " ('jnskr', 1): (0, 0.0, 0.0),\n",
       " ('effici', 1): (0, 0.0, 0.0),\n",
       " ('subgraph', 1): (0, 0.0, 0.0),\n",
       " ('character', 1): (0, None, None),\n",
       " ('memor', 1): (0, 0.0, 0.0),\n",
       " ('strategi', 1): (0, 0.0, 0.0),\n",
       " ('joint', 1): (0, 0.0, 0.0),\n",
       " ('also', 1): (0, 0.0, 0.0),\n",
       " ('paramet', 1): (0, 0.0, 0.0),\n",
       " ('whole', 1): (0, 0.0, 0.0),\n",
       " ('train', 1): (0, 0.0, 0.0),\n",
       " ('includ', 1): (0, 0.0, 0.0),\n",
       " ('non-observ', 1): (0, 0.0, 0.0),\n",
       " ('low', 1): (0, 0.0, 0.0),\n",
       " ('time', 1): (0, 0.0, 0.0),\n",
       " ('complex', 1): (0, 0.0, 0.0),\n",
       " ('two', 1): (0, 0.0, 0.0),\n",
       " ('public', 1): (0, 0.0, 0.0),\n",
       " ('ripplenet', 1): (0, 0.0, 0.0),\n",
       " ('remark', 1): (0, 0.0, 0.0),\n",
       " ('advantag', 1): (0, 0.0, 0.0),\n",
       " ('20', 1): (0, 0.0, 0.0),\n",
       " ('faster', 1): (0, 0.0, 0.0),\n",
       " ('make', 1): (0, 0.0, 0.0),\n",
       " ('real-world', 1): (0, 0.0, 0.0),\n",
       " ('large-scal', 1): (0, None, None),\n",
       " ('order', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('model', 2): (2, 0.09199419632364858, -0.18232484479334335),\n",
       " ('evolut', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('user', 2): (2, 0.09199419632364858, -0.18232484479334335),\n",
       " ('prefer', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('learn', 2): (2, 0.09199419632364858, -0.18232484479334335),\n",
       " ('user-item', 2): (2, 0.11928031367991561, 0.0),\n",
       " ('embed', 2): (1, None, None),\n",
       " ('base', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('time-ord', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('item', 2): (3, 0.13799129448547287, -0.21918617211025843),\n",
       " ('purchas', 2): (1, None, None),\n",
       " ('sequenc', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('defin', 2): (2, 0.17474250108400471, 0.18232484479334335),\n",
       " ('sequenti', 2): (8, 0.6989700043360189, 0.2933109503148185),\n",
       " ('recommend', 2): (3, 0.13799129448547287, -0.21918617211025843),\n",
       " ('sr', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('problem', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('exist', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('method', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('leverag', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('pattern', 2): (6, 0.5242275032520142, 0.27472926204555553),\n",
       " ('transit', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('howev', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('ignor', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('crucial', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('tempor', 2): (8, 0.6989700043360189, 0.2933109503148185),\n",
       " ('collabor', 2): (8, 0.47712125471966244, 0.0),\n",
       " ('signal', 2): (6, 0.5242275032520142, 0.27472926204555553),\n",
       " ('latent', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('evolv', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('interact', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('coexist', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('therefor', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('propos', 2): (2, None, None),\n",
       " ('unifi', 2): (2, 0.17474250108400471, 0.18232484479334335),\n",
       " ('improv', 2): (2, 0.11928031367991561, 0.0),\n",
       " ('qualiti', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('rather', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('challeng', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('firstli', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('hard', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('simultan', 2): (2, 0.17474250108400471, 0.18232484479334335),\n",
       " ('encod', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('secondli', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('non-trivi', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('express', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('effect', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('henc', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('design', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('new', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('framework', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('graph', 2): (3, 0.11288624837399294, -0.5683966251877718),\n",
       " ('tgsrec', 2): (2, 0.17474250108400471, 0.18232484479334335),\n",
       " ('upon', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('continuous-tim', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('bipartit', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('novel', 2): (2, 0.11928031367991561, 0.0),\n",
       " ('transform', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('tct', 2): (3, 0.2621137516260071, 0.21918617211025843),\n",
       " ('layer', 2): (3, 0.2621137516260071, 0.21918617211025843),\n",
       " ('advanc', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('self-attent', 2): (1, None, None),\n",
       " ('mechan', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('adopt', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('attent', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('captur', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('well', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('consid', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('dynam', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('insid', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('propag', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('inform', 2): (1, 0.04599709816182429, -0.12118466246480634),\n",
       " ('empir', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('result', 2): (1, 0.03762874945799765, -0.31425774950285457),\n",
       " ('five', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('dataset', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('show', 2): (1, 0.03762874945799765, -0.31425774950285457),\n",
       " ('modelnam', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('significantli', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('outperform', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('baselin', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('averag', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('22.5%', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('22.1%', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('absolut', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('recal', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('10', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('mrr', 2): (1, 0.08737125054200236, 0.12118466246480634),\n",
       " ('respect', 2): (1, 0.059640156839957804, 0.0),\n",
       " ('knowledg', 2): (0, 0.0, -0.0),\n",
       " ('kg', 2): (0, 0.0, 0.0),\n",
       " ('play', 2): (0, 0.0, 0.0),\n",
       " ('increasingli', 2): (0, 0.0, 0.0),\n",
       " ('import', 2): (0, 0.0, 0.0),\n",
       " ('role', 2): (0, 0.0, 0.0),\n",
       " ('system', 2): (0, 0.0, -0.0),\n",
       " ('recent', 2): (0, 0.0, 0.0),\n",
       " ('technic', 2): (0, 0.0, 0.0),\n",
       " ('trend', 2): (0, 0.0, 0.0),\n",
       " ('develop', 2): (0, 0.0, 0.0),\n",
       " ('end-to-end', 2): (0, 0.0, 0.0),\n",
       " ('found', 2): (0, 0.0, 0.0),\n",
       " ('neural', 2): (0, 0.0, -0.0),\n",
       " ('network', 2): (0, 0.0, 0.0),\n",
       " ('gnn', 2): (0, 0.0, 0.0),\n",
       " ('gnn-base', 2): (0, 0.0, 0.0),\n",
       " ('coarse-grain', 2): (0, 0.0, 0.0),\n",
       " ('relat', 2): (0, 0.0, 0.0),\n",
       " ('fail', 2): (0, 0.0, 0.0),\n",
       " ('1', 2): (0, 0.0, 0.0),\n",
       " ('identifi', 2): (0, 0.0, 0.0),\n",
       " ('fine-grain', 2): (0, 0.0, 0.0),\n",
       " ('level', 2): (0, 0.0, 0.0),\n",
       " ('intent', 2): (0, 0.0, 0.0),\n",
       " ('2', 2): (0, 0.0, 0.0),\n",
       " ('exploit', 2): (0, 0.0, 0.0),\n",
       " ('depend', 2): (0, 0.0, 0.0),\n",
       " ('preserv', 2): (0, 0.0, 0.0),\n",
       " ('semant', 2): (0, 0.0, 0.0),\n",
       " ('long-rang', 2): (0, 0.0, 0.0),\n",
       " ('connect', 2): (0, 0.0, 0.0),\n",
       " ('studi', 2): (0, 0.0, 0.0),\n",
       " ('explor', 2): (0, 0.0, 0.0),\n",
       " ('behind', 2): (0, 0.0, 0.0),\n",
       " ('use', 2): (0, 0.0, 0.0),\n",
       " ('auxiliari', 2): (0, 0.0, 0.0),\n",
       " ('graph-bas', 2): (0, None, None),\n",
       " ('kgin', 2): (0, 0.0, 0.0),\n",
       " ('combin', 2): (0, 0.0, 0.0),\n",
       " ('encourag', 2): (0, 0.0, 0.0),\n",
       " ('independ', 2): (0, 0.0, 0.0),\n",
       " ('differ', 2): (0, 0.0, 0.0),\n",
       " ('better', 2): (0, 0.0, 0.0),\n",
       " ('capabl', 2): (0, 0.0, 0.0),\n",
       " ('interpret', 2): (0, 0.0, 0.0),\n",
       " ('furthermor', 2): (0, 0.0, 0.0),\n",
       " ('devis', 2): (0, None, None),\n",
       " ('aggreg', 2): (0, 0.0, 0.0),\n",
       " ('scheme', 2): (0, 0.0, 0.0),\n",
       " ('recurs', 2): (0, None, None),\n",
       " ('integr', 2): (0, 0.0, 0.0),\n",
       " ('i.e.', 2): (0, 0.0, 0.0),\n",
       " ('path', 2): (0, 0.0, 0.0),\n",
       " ('allow', 2): (0, 0.0, 0.0),\n",
       " ('us', 2): (0, 0.0, 0.0),\n",
       " ('distil', 2): (0, 0.0, 0.0),\n",
       " ('represent', 2): (0, None, None),\n",
       " ('experiment', 2): (0, None, None),\n",
       " ('three', 2): (0, 0.0, 0.0),\n",
       " ('benchmark', 2): (0, 0.0, 0.0),\n",
       " ('achiev', 2): (0, 0.0, 0.0),\n",
       " ('signific', 2): (0, None, None),\n",
       " ('state-of-the-art', 2): (0, 0.0, 0.0),\n",
       " ('like', 2): (0, 0.0, 0.0),\n",
       " ('kgat', 2): (0, 0.0, 0.0),\n",
       " ('41', 2): (0, 0.0, 0.0),\n",
       " ('kgnn-l', 2): (0, 0.0, 0.0),\n",
       " ('38', 2): (0, 0.0, 0.0),\n",
       " ('ckan', 2): (0, 0.0, 0.0),\n",
       " ('47', 2): (0, 0.0, 0.0),\n",
       " ('analys', 2): (0, None, None),\n",
       " ('offer', 2): (0, 0.0, 0.0),\n",
       " ('explan', 2): (0, 0.0, 0.0),\n",
       " ('predict', 2): (0, 0.0, 0.0),\n",
       " ('influenti', 2): (0, 0.0, 0.0),\n",
       " ('motiv', 2): (0, 0.0, 0.0),\n",
       " ('vast', 2): (0, 0.0, 0.0),\n",
       " ('applic', 2): (0, 0.0, 0.0),\n",
       " ('increas', 2): (0, None, None),\n",
       " ('demand', 2): (0, 0.0, 0.0),\n",
       " ('educ', 2): (0, 0.0, 0.0),\n",
       " ('domain', 2): (0, 0.0, 0.0),\n",
       " ('call', 2): (0, 0.0, 0.0),\n",
       " ('knowedu', 2): (0, 0.0, 0.0),\n",
       " ('automat', 2): (0, 0.0, 0.0),\n",
       " ('construct', 2): (0, 0.0, 0.0),\n",
       " ('heterogen', 2): (0, 0.0, 0.0),\n",
       " ('data', 2): (0, 0.0, 0.0),\n",
       " ('e.g.', 2): (0, 0.0, 0.0),\n",
       " ('pedagog', 2): (0, 0.0, 0.0),\n",
       " ('assess', 2): (0, 0.0, 0.0),\n",
       " ('first', 2): (0, 0.0, 0.0),\n",
       " ('extract', 2): (0, 0.0, 0.0),\n",
       " ('concept', 2): (0, 0.0, 0.0),\n",
       " ('subject', 2): (0, 0.0, 0.0),\n",
       " ('cours', 2): (0, None, None),\n",
       " ('specif', 2): (0, 0.0, 0.0),\n",
       " ('label', 2): (0, 0.0, 0.0),\n",
       " ('algorithm', 2): (0, 0.0, 0.0),\n",
       " ('instruct', 2): (0, 0.0, 0.0),\n",
       " ('employ', 2): (0, 0.0, 0.0),\n",
       " ('probabilist', 2): (0, 0.0, 0.0),\n",
       " ('associ', 2): (0, 0.0, 0.0),\n",
       " ('rule', 2): (0, 0.0, 0.0),\n",
       " ('mine', 2): (0, 0.0, 0.0),\n",
       " ('detail', 2): (0, 0.0, 0.0),\n",
       " ('mention', 2): (0, 0.0, 0.0),\n",
       " ('effort', 2): (0, 0.0, 0.0),\n",
       " ('exemplari', 2): (0, 0.0, 0.0),\n",
       " ('case', 2): (0, 0.0, 0.0),\n",
       " ('demonstr', 2): (0, 0.0, 0.0),\n",
       " ('mathemat', 2): (0, 0.0, 0.0),\n",
       " ('prerequisit', 2): (0, 0.0, 0.0),\n",
       " ('deriv', 2): (0, 0.0, 0.0),\n",
       " ('curriculum', 2): (0, 0.0, 0.0),\n",
       " ('standard', 2): (0, 0.0, 0.0),\n",
       " ('concept-bas', 2): (0, None, None),\n",
       " ('perform', 2): (0, 0.0, 0.0),\n",
       " ('student', 2): (0, 0.0, 0.0),\n",
       " ('evalu', 2): (0, 0.0, 0.0),\n",
       " ('f1', 2): (0, 0.0, 0.0),\n",
       " ('score', 2): (0, 0.0, 0.0),\n",
       " ('exce', 2): (0, None, None),\n",
       " ('0.', 2): (0, 0.0, 0.0),\n",
       " ('70', 2): (0, 0.0, 0.0),\n",
       " ('identif', 2): (0, 0.0, 0.0),\n",
       " ('area', 2): (0, 0.0, 0.0),\n",
       " ('curv', 2): (0, 0.0, 0.0),\n",
       " ('mean', 2): (0, 0.0, 0.0),\n",
       " ('precis', 2): (0, None, None),\n",
       " ('95', 2): (0, 0.0, 0.0),\n",
       " ('87', 2): (0, 0.0, 0.0),\n",
       " ('contain', 2): (0, 0.0, 0.0),\n",
       " ('well-structur', 2): (0, 0.0, 0.0),\n",
       " ('extern', 2): (0, 0.0, 0.0),\n",
       " ('shown', 2): (0, 0.0, 0.0),\n",
       " ('high-qual', 2): (0, 0.0, 0.0),\n",
       " ('enhanc', 2): (0, 0.0, 0.0),\n",
       " ('larg', 2): (0, 0.0, 0.0),\n",
       " ('focus', 2): (0, None, None),\n",
       " ('architectur', 2): (0, 0.0, 0.0),\n",
       " ('investig', 2): (0, 0.0, 0.0),\n",
       " ('structur', 2): (0, 0.0, 0.0),\n",
       " ('mainli', 2): (0, 0.0, 0.0),\n",
       " ('reli', 2): (0, 0.0, 0.0),\n",
       " ('neg', 2): (0, 0.0, 0.0),\n",
       " ('sampl', 2): (0, 0.0, 0.0),\n",
       " ('ns', 2): (0, 0.0, 0.0),\n",
       " ('optim', 2): (0, 0.0, 0.0),\n",
       " ('task', 2): (0, 0.0, 0.0),\n",
       " ('sinc', 2): (0, 0.0, 0.0),\n",
       " ('robust', 2): (0, 0.0, 0.0),\n",
       " ('small', 2): (0, 0.0, 0.0),\n",
       " ('fraction', 2): (0, 0.0, 0.0),\n",
       " ('instanc', 2): (0, 0.0, 0.0),\n",
       " ('may', 2): (0, 0.0, 0.0),\n",
       " ('lose', 2): (0, 0.0, 0.0),\n",
       " ('lot', 2): (0, 0.0, 0.0),\n",
       " ('reason', 2): (0, 0.0, 0.0),\n",
       " ('argu', 2): (0, 0.0, 0.0),\n",
       " ('insuffici', 2): (0, 0.0, 0.0),\n",
       " ('among', 2): (0, 0.0, 0.0),\n",
       " ('entiti', 2): (0, 0.0, 0.0),\n",
       " ('paper', 2): (0, 0.0, 0.0),\n",
       " ('jointli', 2): (0, 0.0, 0.0),\n",
       " ('non-sampl', 2): (0, 0.0, 0.0),\n",
       " ('jnskr', 2): (0, 0.0, 0.0),\n",
       " ('effici', 2): (0, 0.0, 0.0),\n",
       " ('subgraph', 2): (0, 0.0, 0.0),\n",
       " ('character', 2): (0, None, None),\n",
       " ('memor', 2): (0, 0.0, 0.0),\n",
       " ('strategi', 2): (0, 0.0, 0.0),\n",
       " ('joint', 2): (0, 0.0, 0.0),\n",
       " ('also', 2): (0, 0.0, 0.0),\n",
       " ('paramet', 2): (0, 0.0, 0.0),\n",
       " ('whole', 2): (0, 0.0, 0.0),\n",
       " ('train', 2): (0, 0.0, 0.0),\n",
       " ('includ', 2): (0, 0.0, 0.0),\n",
       " ('non-observ', 2): (0, 0.0, 0.0),\n",
       " ('low', 2): (0, 0.0, 0.0),\n",
       " ('time', 2): (0, 0.0, 0.0),\n",
       " ('complex', 2): (0, 0.0, 0.0),\n",
       " ('two', 2): (0, 0.0, 0.0),\n",
       " ('public', 2): (0, 0.0, 0.0),\n",
       " ('ripplenet', 2): (0, 0.0, 0.0),\n",
       " ('remark', 2): (0, 0.0, 0.0),\n",
       " ('advantag', 2): (0, 0.0, 0.0),\n",
       " ('20', 2): (0, 0.0, 0.0),\n",
       " ('faster', 2): (0, 0.0, 0.0),\n",
       " ('make', 2): (0, 0.0, 0.0),\n",
       " ('real-world', 2): (0, 0.0, 0.0),\n",
       " ('large-scal', 2): (0, None, None),\n",
       " ('motiv', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('vast', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('applic', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('knowledg', 3): (3, 0.18398839264729716, -0.2312514659878873),\n",
       " ('graph', 3): (3, 0.1505149978319906, -0.5996845128127867),\n",
       " ('increas', 3): (1, None, None),\n",
       " ('demand', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('educ', 3): (5, 0.582475003613349, 0.27162079517973836),\n",
       " ('domain', 3): (2, 0.2329900014453396, 0.19502057866676764),\n",
       " ('propos', 3): (1, None, None),\n",
       " ('system', 3): (2, 0.12265892843153144, -0.19502057866676764),\n",
       " ('call', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('knowedu', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('automat', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('construct', 3): (2, 0.2329900014453396, 0.19502057866676764),\n",
       " ('leverag', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('heterogen', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('data', 3): (6, 0.47712125471966244, 0.0),\n",
       " ('e.g.', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('pedagog', 3): (2, 0.2329900014453396, 0.19502057866676764),\n",
       " ('learn', 3): (2, 0.12265892843153144, -0.19502057866676764),\n",
       " ('assess', 3): (2, 0.2329900014453396, 0.19502057866676764),\n",
       " ('first', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('extract', 3): (3, 0.34948500216800943, 0.2312514659878873),\n",
       " ('concept', 3): (5, 0.582475003613349, 0.27162079517973836),\n",
       " ('subject', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('cours', 3): (1, None, None),\n",
       " ('identifi', 3): (2, 0.15904041823988746, 0.0),\n",
       " ('relat', 3): (4, 0.3180808364797749, 0.0),\n",
       " ('specif', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('adopt', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('neural', 3): (1, 0.06132946421576572, -0.1326653146983143),\n",
       " ('sequenc', 3): (1, 0.06132946421576572, -0.1326653146983143),\n",
       " ('label', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('algorithm', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('instruct', 3): (2, 0.2329900014453396, 0.19502057866676764),\n",
       " ('employ', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('probabilist', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('associ', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('rule', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('mine', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('signific', 3): (1, None, None),\n",
       " ('detail', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('mention', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('effort', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('exemplari', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('case', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('demonstr', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('mathemat', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('prerequisit', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('deriv', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('curriculum', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('standard', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('concept-bas', 3): (1, None, None),\n",
       " ('perform', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('student', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('evalu', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('result', 3): (1, 0.050171665943996864, -0.3440295362978618),\n",
       " ('show', 3): (1, 0.050171665943996864, -0.3440295362978618),\n",
       " ('f1', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('score', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('exce', 3): (1, None, None),\n",
       " ('0.', 3): (3, 0.34948500216800943, 0.2312514659878873),\n",
       " ('70', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('identif', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('area', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('curv', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('mean', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('averag', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('precis', 3): (1, None, None),\n",
       " ('achiev', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('95', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('87', 3): (1, 0.1164950007226698, 0.1326653146983143),\n",
       " ('respect', 3): (1, 0.07952020911994373, 0.0),\n",
       " ('kg', 3): (0, 0.0, 0.0),\n",
       " ('play', 3): (0, 0.0, 0.0),\n",
       " ('increasingli', 3): (0, 0.0, 0.0),\n",
       " ('import', 3): (0, 0.0, 0.0),\n",
       " ('role', 3): (0, 0.0, 0.0),\n",
       " ('recommend', 3): (0, 0.0, -0.0),\n",
       " ('recent', 3): (0, 0.0, 0.0),\n",
       " ('technic', 3): (0, 0.0, 0.0),\n",
       " ('trend', 3): (0, 0.0, 0.0),\n",
       " ('develop', 3): (0, 0.0, 0.0),\n",
       " ('end-to-end', 3): (0, 0.0, 0.0),\n",
       " ('model', 3): (0, 0.0, -0.0),\n",
       " ('found', 3): (0, 0.0, 0.0),\n",
       " ('network', 3): (0, 0.0, 0.0),\n",
       " ('gnn', 3): (0, 0.0, 0.0),\n",
       " ('howev', 3): (0, 0.0, -0.0),\n",
       " ('exist', 3): (0, 0.0, -0.0),\n",
       " ('gnn-base', 3): (0, 0.0, 0.0),\n",
       " ('coarse-grain', 3): (0, 0.0, 0.0),\n",
       " ('fail', 3): (0, 0.0, 0.0),\n",
       " ('1', 3): (0, 0.0, 0.0),\n",
       " ('user-item', 3): (0, 0.0, 0.0),\n",
       " ('fine-grain', 3): (0, 0.0, 0.0),\n",
       " ('level', 3): (0, 0.0, 0.0),\n",
       " ('intent', 3): (0, 0.0, 0.0),\n",
       " ('2', 3): (0, 0.0, 0.0),\n",
       " ('exploit', 3): (0, 0.0, 0.0),\n",
       " ('depend', 3): (0, 0.0, 0.0),\n",
       " ('preserv', 3): (0, 0.0, 0.0),\n",
       " ('semant', 3): (0, 0.0, 0.0),\n",
       " ('long-rang', 3): (0, 0.0, 0.0),\n",
       " ('connect', 3): (0, 0.0, 0.0),\n",
       " ('studi', 3): (0, 0.0, 0.0),\n",
       " ('explor', 3): (0, 0.0, 0.0),\n",
       " ('behind', 3): (0, 0.0, 0.0),\n",
       " ('interact', 3): (0, 0.0, 0.0),\n",
       " ('use', 3): (0, 0.0, 0.0),\n",
       " ('auxiliari', 3): (0, 0.0, 0.0),\n",
       " ('item', 3): (0, 0.0, -0.0),\n",
       " ('new', 3): (0, 0.0, -0.0),\n",
       " ('graph-bas', 3): (0, None, None),\n",
       " ('kgin', 3): (0, 0.0, 0.0),\n",
       " ('attent', 3): (0, 0.0, -0.0),\n",
       " ('combin', 3): (0, 0.0, 0.0),\n",
       " ('encourag', 3): (0, 0.0, 0.0),\n",
       " ('independ', 3): (0, 0.0, 0.0),\n",
       " ('differ', 3): (0, 0.0, 0.0),\n",
       " ('better', 3): (0, 0.0, 0.0),\n",
       " ('capabl', 3): (0, 0.0, 0.0),\n",
       " ('interpret', 3): (0, 0.0, 0.0),\n",
       " ('furthermor', 3): (0, 0.0, 0.0),\n",
       " ('devis', 3): (0, None, None),\n",
       " ('inform', 3): (0, 0.0, -0.0),\n",
       " ('aggreg', 3): (0, 0.0, 0.0),\n",
       " ('scheme', 3): (0, 0.0, 0.0),\n",
       " ('recurs', 3): (0, None, None),\n",
       " ('integr', 3): (0, 0.0, 0.0),\n",
       " ('i.e.', 3): (0, 0.0, 0.0),\n",
       " ('path', 3): (0, 0.0, 0.0),\n",
       " ('allow', 3): (0, 0.0, 0.0),\n",
       " ('us', 3): (0, 0.0, 0.0),\n",
       " ('distil', 3): (0, 0.0, 0.0),\n",
       " ('user', 3): (0, 0.0, -0.0),\n",
       " ('encod', 3): (0, 0.0, -0.0),\n",
       " ('represent', 3): (0, None, None),\n",
       " ('experiment', 3): (0, None, None),\n",
       " ('three', 3): (0, 0.0, 0.0),\n",
       " ('benchmark', 3): (0, 0.0, 0.0),\n",
       " ('dataset', 3): (0, 0.0, 0.0),\n",
       " ('improv', 3): (0, 0.0, 0.0),\n",
       " ('state-of-the-art', 3): (0, 0.0, 0.0),\n",
       " ('method', 3): (0, 0.0, -0.0),\n",
       " ('like', 3): (0, 0.0, 0.0),\n",
       " ('kgat', 3): (0, 0.0, 0.0),\n",
       " ('41', 3): (0, 0.0, 0.0),\n",
       " ('kgnn-l', 3): (0, 0.0, 0.0),\n",
       " ('38', 3): (0, 0.0, 0.0),\n",
       " ('ckan', 3): (0, 0.0, 0.0),\n",
       " ('47', 3): (0, 0.0, 0.0),\n",
       " ('analys', 3): (0, None, None),\n",
       " ('offer', 3): (0, 0.0, 0.0),\n",
       " ('explan', 3): (0, 0.0, 0.0),\n",
       " ('predict', 3): (0, 0.0, 0.0),\n",
       " ('influenti', 3): (0, 0.0, 0.0),\n",
       " ('order', 3): (0, 0.0, 0.0),\n",
       " ('evolut', 3): (0, 0.0, 0.0),\n",
       " ('prefer', 3): (0, 0.0, 0.0),\n",
       " ('embed', 3): (0, None, None),\n",
       " ('base', 3): (0, 0.0, 0.0),\n",
       " ('time-ord', 3): (0, 0.0, 0.0),\n",
       " ('purchas', 3): (0, None, None),\n",
       " ('defin', 3): (0, 0.0, 0.0),\n",
       " ('sequenti', 3): (0, 0.0, 0.0),\n",
       " ('sr', 3): (0, 0.0, 0.0),\n",
       " ('problem', 3): (0, 0.0, 0.0),\n",
       " ('pattern', 3): (0, 0.0, 0.0),\n",
       " ('transit', 3): (0, 0.0, 0.0),\n",
       " ('ignor', 3): (0, 0.0, 0.0),\n",
       " ('crucial', 3): (0, 0.0, 0.0),\n",
       " ('tempor', 3): (0, 0.0, 0.0),\n",
       " ('collabor', 3): (0, 0.0, 0.0),\n",
       " ('signal', 3): (0, 0.0, 0.0),\n",
       " ('latent', 3): (0, 0.0, 0.0),\n",
       " ('evolv', 3): (0, 0.0, 0.0),\n",
       " ('coexist', 3): (0, 0.0, 0.0),\n",
       " ('therefor', 3): (0, 0.0, 0.0),\n",
       " ('unifi', 3): (0, 0.0, 0.0),\n",
       " ('qualiti', 3): (0, 0.0, 0.0),\n",
       " ('rather', 3): (0, 0.0, 0.0),\n",
       " ('challeng', 3): (0, 0.0, 0.0),\n",
       " ('firstli', 3): (0, 0.0, 0.0),\n",
       " ('hard', 3): (0, 0.0, 0.0),\n",
       " ('simultan', 3): (0, 0.0, 0.0),\n",
       " ('secondli', 3): (0, 0.0, 0.0),\n",
       " ('non-trivi', 3): (0, 0.0, 0.0),\n",
       " ('express', 3): (0, 0.0, 0.0),\n",
       " ('effect', 3): (0, 0.0, 0.0),\n",
       " ('henc', 3): (0, 0.0, 0.0),\n",
       " ('design', 3): (0, 0.0, 0.0),\n",
       " ('framework', 3): (0, 0.0, 0.0),\n",
       " ('tgsrec', 3): (0, 0.0, 0.0),\n",
       " ('upon', 3): (0, 0.0, 0.0),\n",
       " ('continuous-tim', 3): (0, 0.0, 0.0),\n",
       " ('bipartit', 3): (0, 0.0, 0.0),\n",
       " ('novel', 3): (0, 0.0, 0.0),\n",
       " ('transform', 3): (0, 0.0, 0.0),\n",
       " ('tct', 3): (0, 0.0, 0.0),\n",
       " ('layer', 3): (0, 0.0, 0.0),\n",
       " ('advanc', 3): (0, 0.0, 0.0),\n",
       " ('self-attent', 3): (0, None, None),\n",
       " ('mechan', 3): (0, 0.0, 0.0),\n",
       " ('captur', 3): (0, 0.0, 0.0),\n",
       " ('well', 3): (0, 0.0, 0.0),\n",
       " ('consid', 3): (0, 0.0, 0.0),\n",
       " ('dynam', 3): (0, 0.0, 0.0),\n",
       " ('insid', 3): (0, 0.0, 0.0),\n",
       " ('propag', 3): (0, 0.0, 0.0),\n",
       " ('empir', 3): (0, 0.0, 0.0),\n",
       " ('five', 3): (0, 0.0, 0.0),\n",
       " ('modelnam', 3): (0, 0.0, 0.0),\n",
       " ('significantli', 3): (0, 0.0, 0.0),\n",
       " ('outperform', 3): (0, 0.0, 0.0),\n",
       " ('baselin', 3): (0, 0.0, 0.0),\n",
       " ('22.5%', 3): (0, 0.0, 0.0),\n",
       " ('22.1%', 3): (0, 0.0, 0.0),\n",
       " ('absolut', 3): (0, 0.0, 0.0),\n",
       " ('recal', 3): (0, 0.0, 0.0),\n",
       " ('10', 3): (0, 0.0, 0.0),\n",
       " ('mrr', 3): (0, 0.0, 0.0),\n",
       " ('contain', 3): (0, 0.0, 0.0),\n",
       " ('well-structur', 3): (0, 0.0, 0.0),\n",
       " ('extern', 3): (0, 0.0, 0.0),\n",
       " ('shown', 3): (0, 0.0, 0.0),\n",
       " ('high-qual', 3): (0, 0.0, 0.0),\n",
       " ('enhanc', 3): (0, 0.0, 0.0),\n",
       " ('larg', 3): (0, 0.0, 0.0),\n",
       " ('focus', 3): (0, None, None),\n",
       " ('architectur', 3): (0, 0.0, 0.0),\n",
       " ('investig', 3): (0, 0.0, 0.0),\n",
       " ('structur', 3): (0, 0.0, 0.0),\n",
       " ('mainli', 3): (0, 0.0, 0.0),\n",
       " ('reli', 3): (0, 0.0, 0.0),\n",
       " ('neg', 3): (0, 0.0, 0.0),\n",
       " ('sampl', 3): (0, 0.0, 0.0),\n",
       " ('ns', 3): (0, 0.0, 0.0),\n",
       " ('optim', 3): (0, 0.0, 0.0),\n",
       " ('task', 3): (0, 0.0, 0.0),\n",
       " ('sinc', 3): (0, 0.0, 0.0),\n",
       " ('robust', 3): (0, 0.0, 0.0),\n",
       " ('small', 3): (0, 0.0, 0.0),\n",
       " ('fraction', 3): (0, 0.0, 0.0),\n",
       " ('instanc', 3): (0, 0.0, 0.0),\n",
       " ('may', 3): (0, 0.0, 0.0),\n",
       " ('lose', 3): (0, 0.0, 0.0),\n",
       " ('lot', 3): (0, 0.0, 0.0),\n",
       " ('reason', 3): (0, 0.0, 0.0),\n",
       " ('argu', 3): (0, 0.0, 0.0),\n",
       " ('insuffici', 3): (0, 0.0, 0.0),\n",
       " ('among', 3): (0, 0.0, 0.0),\n",
       " ('entiti', 3): (0, 0.0, 0.0),\n",
       " ('paper', 3): (0, 0.0, 0.0),\n",
       " ('jointli', 3): (0, 0.0, 0.0),\n",
       " ('non-sampl', 3): (0, 0.0, 0.0),\n",
       " ('jnskr', 3): (0, 0.0, 0.0),\n",
       " ('effici', 3): (0, 0.0, 0.0),\n",
       " ('subgraph', 3): (0, 0.0, 0.0),\n",
       " ('character', 3): (0, None, None),\n",
       " ('memor', 3): (0, 0.0, 0.0),\n",
       " ('strategi', 3): (0, 0.0, 0.0),\n",
       " ('joint', 3): (0, 0.0, 0.0),\n",
       " ('also', 3): (0, 0.0, 0.0),\n",
       " ('paramet', 3): (0, 0.0, 0.0),\n",
       " ('whole', 3): (0, 0.0, 0.0),\n",
       " ('train', 3): (0, 0.0, 0.0),\n",
       " ('includ', 3): (0, 0.0, 0.0),\n",
       " ('non-observ', 3): (0, 0.0, 0.0),\n",
       " ('low', 3): (0, 0.0, 0.0),\n",
       " ('time', 3): (0, 0.0, 0.0),\n",
       " ('complex', 3): (0, 0.0, 0.0),\n",
       " ('two', 3): (0, 0.0, 0.0),\n",
       " ('public', 3): (0, 0.0, 0.0),\n",
       " ('ripplenet', 3): (0, 0.0, 0.0),\n",
       " ('remark', 3): (0, 0.0, 0.0),\n",
       " ('advantag', 3): (0, 0.0, 0.0),\n",
       " ('20', 3): (0, 0.0, 0.0),\n",
       " ('faster', 3): (0, 0.0, 0.0),\n",
       " ('make', 3): (0, 0.0, 0.0),\n",
       " ('real-world', 3): (0, 0.0, 0.0),\n",
       " ('large-scal', 3): (0, None, None),\n",
       " ('knowledg', 4): (3, 0.22078607117675658, -0.21211565042928232),\n",
       " ('graph', 4): (3, 0.1806179973983887, -0.5500612501817146),\n",
       " ('kg', 4): (4, 0.38169700377572996, 0.0),\n",
       " ('contain', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('well-structur', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('extern', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('inform', 4): (4, 0.2943814282356755, -0.23723679804875028),\n",
       " ('shown', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('effect', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('high-qual', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('recommend', 4): (4, 0.2943814282356755, -0.23723679804875028),\n",
       " ('howev', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('exist', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('enhanc', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('method', 4): (4, 0.2943814282356755, -0.23723679804875028),\n",
       " ('larg', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('focus', 4): (1, None, None),\n",
       " ('explor', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('advanc', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('neural', 4): (2, 0.14719071411783774, -0.1750445124491647),\n",
       " ('network', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('architectur', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('better', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('investig', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('structur', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('model', 4): (5, 0.3679767852945943, -0.2553840911112433),\n",
       " ('learn', 4): (5, 0.3679767852945943, -0.2553840911112433),\n",
       " ('mainli', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('reli', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('neg', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('sampl', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('ns', 4): (3, 0.4193820026016113, 0.21211565042928232),\n",
       " ('optim', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('embed', 4): (2, None, None),\n",
       " ('task', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('sinc', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('robust', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('e.g.', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('small', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('fraction', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('instanc', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('may', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('lose', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('lot', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('use', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('reason', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('argu', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('insuffici', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('captur', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('collabor', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('among', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('user', 4): (3, 0.22078607117675658, -0.21211565042928232),\n",
       " ('item', 4): (3, 0.22078607117675658, -0.21211565042928232),\n",
       " ('entiti', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('paper', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('propos', 4): (2, None, None),\n",
       " ('novel', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('jointli', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('non-sampl', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('jnskr', 4): (4, 0.5591760034688151, 0.23723679804875028),\n",
       " ('specif', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('first', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('design', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('new', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('effici', 4): (3, 0.4193820026016113, 0.21211565042928232),\n",
       " ('algorithm', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('subgraph', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('encod', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('attent', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('character', 4): (1, None, None),\n",
       " ('prefer', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('memor', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('strategi', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('joint', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('framework', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('fine-grain', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('connect', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('also', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('paramet', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('whole', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('train', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('data', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('includ', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('non-observ', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('rather', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('low', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('time', 4): (2, 0.27958800173440757, 0.1750445124491647),\n",
       " ('complex', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('experiment', 4): (1, None, None),\n",
       " ('result', 4): (1, 0.06020599913279624, -0.29779322048562074),\n",
       " ('two', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('public', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('benchmark', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('show', 4): (2, 0.12041199826559248, -0.45392786039301214),\n",
       " ('significantli', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('outperform', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('state-of-the-art', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('like', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('ripplenet', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('kgat', 4): (2, 0.19084850188786498, 0.0),\n",
       " ('remark', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('signific', 4): (1, None, None),\n",
       " ('advantag', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('20', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('faster', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('make', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('applic', 4): (1, 0.09542425094393249, 0.0),\n",
       " ('real-world', 4): (1, 0.13979400086720378, 0.1148355799210921),\n",
       " ('large-scal', 4): (1, None, None),\n",
       " ('system', 4): (1, 0.07359535705891887, -0.1148355799210921),\n",
       " ('play', 4): (0, 0.0, 0.0),\n",
       " ('increasingli', 4): (0, 0.0, 0.0),\n",
       " ('import', 4): (0, 0.0, 0.0),\n",
       " ('role', 4): (0, 0.0, 0.0),\n",
       " ('recent', 4): (0, 0.0, 0.0),\n",
       " ('technic', 4): (0, 0.0, 0.0),\n",
       " ('trend', 4): (0, 0.0, 0.0),\n",
       " ('develop', 4): (0, 0.0, 0.0),\n",
       " ('end-to-end', 4): (0, 0.0, 0.0),\n",
       " ('found', 4): (0, 0.0, 0.0),\n",
       " ('gnn', 4): (0, 0.0, 0.0),\n",
       " ('gnn-base', 4): (0, 0.0, 0.0),\n",
       " ('coarse-grain', 4): (0, 0.0, 0.0),\n",
       " ('relat', 4): (0, 0.0, 0.0),\n",
       " ('fail', 4): (0, 0.0, 0.0),\n",
       " ('1', 4): (0, 0.0, 0.0),\n",
       " ('identifi', 4): (0, 0.0, 0.0),\n",
       " ('user-item', 4): (0, 0.0, 0.0),\n",
       " ('level', 4): (0, 0.0, 0.0),\n",
       " ('intent', 4): (0, 0.0, 0.0),\n",
       " ('2', 4): (0, 0.0, 0.0),\n",
       " ('exploit', 4): (0, 0.0, 0.0),\n",
       " ('depend', 4): (0, 0.0, 0.0),\n",
       " ('preserv', 4): (0, 0.0, 0.0),\n",
       " ('semant', 4): (0, 0.0, 0.0),\n",
       " ('long-rang', 4): (0, 0.0, 0.0),\n",
       " ('studi', 4): (0, 0.0, 0.0),\n",
       " ('behind', 4): (0, 0.0, 0.0),\n",
       " ('interact', 4): (0, 0.0, 0.0),\n",
       " ('auxiliari', 4): (0, 0.0, 0.0),\n",
       " ('graph-bas', 4): (0, None, None),\n",
       " ('kgin', 4): (0, 0.0, 0.0),\n",
       " ('combin', 4): (0, 0.0, 0.0),\n",
       " ('encourag', 4): (0, 0.0, 0.0),\n",
       " ('independ', 4): (0, 0.0, 0.0),\n",
       " ('differ', 4): (0, 0.0, 0.0),\n",
       " ('capabl', 4): (0, 0.0, 0.0),\n",
       " ('interpret', 4): (0, 0.0, 0.0),\n",
       " ('furthermor', 4): (0, 0.0, 0.0),\n",
       " ('devis', 4): (0, None, None),\n",
       " ('aggreg', 4): (0, 0.0, 0.0),\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#terme docu = poid frequence\n",
    "def make_struct_dico(dico):\n",
    "        dict_copy = {}\n",
    "        for each in dico.keys():\n",
    "                poid_simple = poid(dico, each[0], (each[1]))\n",
    "                poid_normal = poid_normalise(dico,each[0], each[1])\n",
    "                dict_copy[each] = (dico[each], poid_simple, poid_normal)\n",
    "        return dict_copy\n",
    "\n",
    "make_struct_dico(TermesFrequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('graph', 1): (2, 0.08600857018970891, -0.47886895162339743),\n",
       " ('graph', 2): (3, 0.11288624837399294, -0.5683966251877718),\n",
       " ('graph', 3): (3, 0.1505149978319906, -0.5996845128127867),\n",
       " ('graph', 4): (3, 0.1806179973983887, -0.5500612501817146),\n",
       " ('recommend', 1): (1, 0.05256811218494204, -0.12325872759256586),\n",
       " ('recommend', 2): (3, 0.13799129448547287, -0.21918617211025843),\n",
       " ('recommend', 3): (0, 0.0, -0.0),\n",
       " ('recommend', 4): (4, 0.2943814282356755, -0.23723679804875028),\n",
       " ('result', 1): (1, 0.043004285094854454, -0.31963624399312346),\n",
       " ('result', 2): (1, 0.03762874945799765, -0.31425774950285457),\n",
       " ('result', 3): (1, 0.050171665943996864, -0.3440295362978618),\n",
       " ('result', 4): (1, 0.06020599913279624, -0.29779322048562074)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_struct_dico_req(dico, query):\n",
    "        dict_copy = {}\n",
    "        words = query.split(\" \")\n",
    "        new_words = []\n",
    "        for terme in words:\n",
    "                temp = terme.strip()\n",
    "                new_words.append(Porter.stem(temp.lower()))\n",
    "        \n",
    "        \n",
    "        for each in dico.keys():\n",
    "                if each[0] in new_words:\n",
    "                        poid_simple = poid(dico, each[0], (each[1]))\n",
    "                        poid_normal = poid_normalise(dico,each[0], each[1])\n",
    "                        dict_copy[each] = (dico[each], poid_simple, poid_normal)\n",
    "        result = {}\n",
    "        for x in sorted(dict_copy):\n",
    "                result[x] = dict_copy[x]\n",
    "        return result, dict_copy\n",
    "\n",
    "weights_and_words = make_struct_dico_req(TermesFrequence, \"results recommendation graph\")\n",
    "make_struct_dico_req(TermesFrequence, \"results recommendation graph\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, (3.3545874273684717, 0.5352054247668604)),\n",
       " (2, (3.1505149978319906, 0.2885062923174635)),\n",
       " (3, (3.050171665943997, 0.20068666377598746)),\n",
       " (1, (2.095572397279797, 0.18158096746950542))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "def sorted_weights(dico, query):\n",
    "        weights_and_words = make_struct_dico_req(dico, query)[1]\n",
    "        docus_ordonnes = {}\n",
    "        for each in weights_and_words.keys():\n",
    "                if(each[1] not in docus_ordonnes.keys()):\n",
    "                        docus_ordonnes[each[1]] = (weights_and_words[each][0],weights_and_words[each][1])\n",
    "                else: \n",
    "                        docus_ordonnes[each[1]] = (docus_ordonnes[each[1]][0]+weights_and_words[each][1],docus_ordonnes[each[1]][1]+weights_and_words[each][1])\n",
    "        result = {}\n",
    "        result =  sorted(docus_ordonnes.items(), key = operator.itemgetter(1), reverse = True)\n",
    "                \n",
    "        return result\n",
    "sorted_weights(TermesFrequence, \"results recommendation graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1.856625552675464, 1.9637030438614036), 2: (2.518932543005818, 1.9880727055659513), 3: (2.2128881677699273, 1.856956118871697), 4: (3.6433958548462106, 2.1742381062388576)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, (1.1838152267931743, 0.08502704095015205)),\n",
       " (2, (1.1460739874085846, 0.11813498507116373)),\n",
       " (4, (1.0146711391029961, 0.2095590050649827)),\n",
       " (1, (0.887932352825952, 0.0748120906959923))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relevence(dico, query):\n",
    "        weights_and_words = make_struct_dico_req(dico, query)[1]\n",
    "        docus_ordonnes = {}\n",
    "        \n",
    "        words = query.split(\" \")\n",
    "        word_count = len(words)\n",
    "        dicto = make_struct_dico(dico)\n",
    "        sums = {}\n",
    "        for each in dicto.keys():\n",
    "                try:\n",
    "                        if each[1] in sums.keys():\n",
    "                                sums[each[1]] = (sums[each[1]][0] + dicto[each][1]**2, sums[each[1]][1] + dicto[each][2]**2)\n",
    "                        else: sums[each[1]] = (dicto[each][1]**2, dicto[each][2]**2)\n",
    "                except: pass\n",
    "        print(sums)\n",
    "        for each in weights_and_words.keys():\n",
    "                if(each[1] not in docus_ordonnes.keys()):\n",
    "                        docus_ordonnes[each[1]] = (weights_and_words[each][0],weights_and_words[each][1])\n",
    "                else: \n",
    "                        docus_ordonnes[each[1]] = (docus_ordonnes[each[1]][0]+weights_and_words[each][1],docus_ordonnes[each[1]][1]+weights_and_words[each][1])\n",
    "        \n",
    "        relevence = {}\n",
    "        for each in docus_ordonnes.keys():\n",
    "                relevence[each] = (docus_ordonnes[each][0]/(np.sqrt(sums[each][0])*np.sqrt(word_count)), docus_ordonnes[each][1]/(np.sqrt(sums[each][1])*np.sqrt(word_count)))\n",
    "        relevence =  sorted(relevence.items(), key = operator.itemgetter(1), reverse = True)\n",
    "        return relevence\n",
    "\n",
    "relevence(TermesFrequence, \"results recommendation graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pertinence(dico, query):\n",
    "        query = query.lower()\n",
    "\n",
    "        words = query.replace(\"and\", \"\")\n",
    "        words = words.replace(\"or\", \"\")\n",
    "        words = words.replace(\"not\", \"\")\n",
    "        words = re.sub(' +',' ', words)\n",
    "        words = words.strip()\n",
    "        print(words)\n",
    "        query = query.strip()\n",
    "        all_words = query.split(\" \")\n",
    "        words = words.split(\" \")\n",
    "        logic_gates = [word for word in all_words if word not in words]\n",
    "        \n",
    "        print(logic_gates)\n",
    "        words_and_freqs = {}\n",
    "        print(words)\n",
    "        for word in words:\n",
    "                frequencies = freq2(dico, word)\n",
    "                print(frequencies)\n",
    "                for each in frequencies.keys():\n",
    "                        if frequencies[each] != 0:\n",
    "                                if word in words_and_freqs:\n",
    "                                        words_and_freqs[word].append(each)\n",
    "                                else: words_and_freqs[word] = [each]\n",
    "        inters = list(words_and_freqs.values())\n",
    "        print(len(logic_gates))\n",
    "        for i in range(len(logic_gates)-1):\n",
    "                if logic_gates[i] == 'and':\n",
    "                        if i< len(logic_gates):\n",
    "                                if logic_gates[i+1] == 'not':\n",
    "                                        inter_plus = [docu for docu in [1,2,3,4] if docu not in inters[i+1]]\n",
    "                                        if i == 0:\n",
    "                                                past_gate = set(inters[i]).intersection(inter_plus)\n",
    "                                        else: past_gate = set(past_gate).intersection(inter_plus)\n",
    "                                else: \n",
    "                                        if i == 0:\n",
    "                                                past_gate = set(inters[i]).intersection(inters[i+1])\n",
    "                                        else: past_gate = set(past_gate).intersection(inters[i+1])\n",
    "                                        print('a')\n",
    "                elif logic_gates[i] == 'or':\n",
    "                        if i< len(logic_gates):\n",
    "                                if logic_gates[i+1] == 'not':\n",
    "                                        inter_plus = [docu for docu in [1,2,3,4] if docu not in inters[i+1]]\n",
    "                                        if i == 0:\n",
    "                                                past_gate = set(np.sum(inters[i],inter_plus))\n",
    "                                        else: past_gate = np.sum(past_gate,inter_plus)\n",
    "                                else: \n",
    "                                        if i == 0:\n",
    "                                                past_gate = set(np.sum(inters[i],inters[i+1]))\n",
    "                                        else: past_gate = np.sum(past_gate,inters[i+1])\n",
    "        print(past_gate)\n",
    "\n",
    "        # for i in range(len(inters)-1):\n",
    "        #         if i == 0:\n",
    "        #                 intersection = set(inters[i]).intersection(inters[i+1])\n",
    "        #         else: intersection = set(intersection).intersection(inters[i+1])\n",
    "        # print(intersection)\n",
    "\n",
    "        # print(set(np.sum(inters, dtype = object)))\n",
    "        # print(words_and_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results recommendation\n",
      "['and']\n",
      "['results', 'recommendation']\n",
      "{1: 1, 2: 1, 3: 1, 4: 1}\n",
      "{1: 1, 2: 3, 3: 0, 4: 4}\n",
      "1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'past_gate' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-060bede59556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpertinence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTermesFrequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"results and recommendation \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-118-cbc4a38a9dbe>\u001b[0m in \u001b[0;36mpertinence\u001b[1;34m(dico, query)\u001b[0m\n\u001b[0;32m     50\u001b[0m                                                 \u001b[0mpast_gate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpast_gate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_gate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast_gate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# for i in range(len(inters)-1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'past_gate' referenced before assignment"
     ]
    }
   ],
   "source": [
    "pertinence(TermesFrequence, \"results and recommendation \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21678382654e3eb753a0b0c898548b9c6845121cc826911b0d178654f0c6a6c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
